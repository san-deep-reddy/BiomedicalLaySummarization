{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-07-09 14:36:37.177174: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-09 14:36:37.975548: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x720c3ede1990>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, \"/home/ubuntu/adapters/src\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import adapters\n",
    "from adapters import AutoAdapterModel, AdapterTrainer, SeqBnConfig, Seq2SeqAdapterTrainer\n",
    "import adapters.composition as ac\n",
    "from adapters.composition import Fuse\n",
    "import peft, torch\n",
    "from transformers import (AutoTokenizer, \n",
    "                          AutoModel,\n",
    "                          AutoModelForSeq2SeqLM,\n",
    "                          BartForConditionalGeneration,\n",
    "                          Seq2SeqTrainer, \n",
    "                          Seq2SeqTrainingArguments,\n",
    "                          DataCollatorForSeq2Seq,\n",
    "                          EarlyStoppingCallback,\n",
    "                          set_seed,\n",
    "                          Trainer\n",
    "                         )\n",
    "from datasets import Dataset, DatasetDict\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "adapters.__file__\n",
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = BartForConditionalGeneration.from_pretrained(\"ireneli1024/bart-large-PLOS-finetuned\") \n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"ireneli1024/bart-large-PLOS-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoAdapterModel.from_pretrained(\"/opt/dlami/nvme/no_fusion_layer/knowledge_consolidation\").to(device) #AutoAdapterModel.from_pretrained(\"/opt/dlami/nvme/knowledge_consolidation/checkpoint-7956\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/opt/dlami/nvme/no_fusion_layer/knowledge_consolidation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete_head('knowledge_consolidation')\n",
    "adapter_setup = Fuse(\"adapter1\", \"adapter2\", \"adapter3\")    \n",
    "model.add_seq2seq_lm_head('fine_tunning')\n",
    "model.train_adapter_fusion([adapter_setup, 'adapter1', 'adapter2', 'adapter3'], unfreeze_adapters=True, train_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_layers_trainable(model):\n",
    "    # Set all parameters to require gradients (trainable)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Example usage assuming `model` is your instantiated model\n",
    "make_all_layers_trainable(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters:\n",
      "model.shared.weight: torch.Size([50265, 768])\n",
      "model.encoder.embed_positions.weight: torch.Size([1026, 768])\n",
      "model.encoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.0.self_attn.k_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.0.self_attn.v_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.0.self_attn.q_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.0.self_attn.out_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.0.self_attn_layer_norm.weight: torch.Size([768])\n",
      "model.encoder.layers.0.self_attn_layer_norm.bias: torch.Size([768])\n",
      "model.encoder.layers.0.fc1.weight: torch.Size([3072, 768])\n",
      "model.encoder.layers.0.fc1.bias: torch.Size([3072])\n",
      "model.encoder.layers.0.fc2.weight: torch.Size([768, 3072])\n",
      "model.encoder.layers.0.fc2.bias: torch.Size([768])\n",
      "model.encoder.layers.0.final_layer_norm.weight: torch.Size([768])\n",
      "model.encoder.layers.0.final_layer_norm.bias: torch.Size([768])\n",
      "model.encoder.layers.0.output_adapters.adapters.adapter1.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.encoder.layers.0.output_adapters.adapters.adapter1.adapter_down.0.bias: torch.Size([48])\n",
      "model.encoder.layers.0.output_adapters.adapters.adapter1.adapter_up.weight: torch.Size([768, 48])\n",
      "model.encoder.layers.0.output_adapters.adapters.adapter1.adapter_up.bias: torch.Size([768])\n",
      "model.encoder.layers.0.output_adapters.adapters.adapter2.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.encoder.layers.0.output_adapters.adapters.adapter2.adapter_down.0.bias: torch.Size([48])\n",
      "model.encoder.layers.0.output_adapters.adapters.adapter2.adapter_up.weight: torch.Size([768, 48])\n",
      "model.encoder.layers.0.output_adapters.adapters.adapter2.adapter_up.bias: torch.Size([768])\n",
      "model.encoder.layers.0.output_adapters.adapters.adapter3.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.encoder.layers.0.output_adapters.adapters.adapter3.adapter_down.0.bias: torch.Size([48])\n",
      "model.encoder.layers.0.output_adapters.adapters.adapter3.adapter_up.weight: torch.Size([768, 48])\n",
      "model.encoder.layers.0.output_adapters.adapters.adapter3.adapter_up.bias: torch.Size([768])\n",
      "model.encoder.layers.0.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.0.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.bias: torch.Size([768])\n",
      "model.encoder.layers.0.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.0.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.bias: torch.Size([768])\n",
      "model.encoder.layers.0.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.value.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.1.self_attn.k_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.1.self_attn.v_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.1.self_attn.q_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.1.self_attn.out_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.1.self_attn_layer_norm.weight: torch.Size([768])\n",
      "model.encoder.layers.1.self_attn_layer_norm.bias: torch.Size([768])\n",
      "model.encoder.layers.1.fc1.weight: torch.Size([3072, 768])\n",
      "model.encoder.layers.1.fc1.bias: torch.Size([3072])\n",
      "model.encoder.layers.1.fc2.weight: torch.Size([768, 3072])\n",
      "model.encoder.layers.1.fc2.bias: torch.Size([768])\n",
      "model.encoder.layers.1.final_layer_norm.weight: torch.Size([768])\n",
      "model.encoder.layers.1.final_layer_norm.bias: torch.Size([768])\n",
      "model.encoder.layers.1.output_adapters.adapters.adapter1.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.encoder.layers.1.output_adapters.adapters.adapter1.adapter_down.0.bias: torch.Size([48])\n",
      "model.encoder.layers.1.output_adapters.adapters.adapter1.adapter_up.weight: torch.Size([768, 48])\n",
      "model.encoder.layers.1.output_adapters.adapters.adapter1.adapter_up.bias: torch.Size([768])\n",
      "model.encoder.layers.1.output_adapters.adapters.adapter2.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.encoder.layers.1.output_adapters.adapters.adapter2.adapter_down.0.bias: torch.Size([48])\n",
      "model.encoder.layers.1.output_adapters.adapters.adapter2.adapter_up.weight: torch.Size([768, 48])\n",
      "model.encoder.layers.1.output_adapters.adapters.adapter2.adapter_up.bias: torch.Size([768])\n",
      "model.encoder.layers.1.output_adapters.adapters.adapter3.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.encoder.layers.1.output_adapters.adapters.adapter3.adapter_down.0.bias: torch.Size([48])\n",
      "model.encoder.layers.1.output_adapters.adapters.adapter3.adapter_up.weight: torch.Size([768, 48])\n",
      "model.encoder.layers.1.output_adapters.adapters.adapter3.adapter_up.bias: torch.Size([768])\n",
      "model.encoder.layers.1.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.1.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.bias: torch.Size([768])\n",
      "model.encoder.layers.1.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.1.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.bias: torch.Size([768])\n",
      "model.encoder.layers.1.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.value.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.2.self_attn.k_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.2.self_attn.v_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.2.self_attn.q_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.2.self_attn.out_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.2.self_attn_layer_norm.weight: torch.Size([768])\n",
      "model.encoder.layers.2.self_attn_layer_norm.bias: torch.Size([768])\n",
      "model.encoder.layers.2.fc1.weight: torch.Size([3072, 768])\n",
      "model.encoder.layers.2.fc1.bias: torch.Size([3072])\n",
      "model.encoder.layers.2.fc2.weight: torch.Size([768, 3072])\n",
      "model.encoder.layers.2.fc2.bias: torch.Size([768])\n",
      "model.encoder.layers.2.final_layer_norm.weight: torch.Size([768])\n",
      "model.encoder.layers.2.final_layer_norm.bias: torch.Size([768])\n",
      "model.encoder.layers.2.output_adapters.adapters.adapter1.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.encoder.layers.2.output_adapters.adapters.adapter1.adapter_down.0.bias: torch.Size([48])\n",
      "model.encoder.layers.2.output_adapters.adapters.adapter1.adapter_up.weight: torch.Size([768, 48])\n",
      "model.encoder.layers.2.output_adapters.adapters.adapter1.adapter_up.bias: torch.Size([768])\n",
      "model.encoder.layers.2.output_adapters.adapters.adapter2.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.encoder.layers.2.output_adapters.adapters.adapter2.adapter_down.0.bias: torch.Size([48])\n",
      "model.encoder.layers.2.output_adapters.adapters.adapter2.adapter_up.weight: torch.Size([768, 48])\n",
      "model.encoder.layers.2.output_adapters.adapters.adapter2.adapter_up.bias: torch.Size([768])\n",
      "model.encoder.layers.2.output_adapters.adapters.adapter3.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.encoder.layers.2.output_adapters.adapters.adapter3.adapter_down.0.bias: torch.Size([48])\n",
      "model.encoder.layers.2.output_adapters.adapters.adapter3.adapter_up.weight: torch.Size([768, 48])\n",
      "model.encoder.layers.2.output_adapters.adapters.adapter3.adapter_up.bias: torch.Size([768])\n",
      "model.encoder.layers.2.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.2.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.bias: torch.Size([768])\n",
      "model.encoder.layers.2.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.2.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.bias: torch.Size([768])\n",
      "model.encoder.layers.2.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.value.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.3.self_attn.k_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.3.self_attn.v_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.3.self_attn.q_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.3.self_attn.out_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.3.self_attn_layer_norm.weight: torch.Size([768])\n",
      "model.encoder.layers.3.self_attn_layer_norm.bias: torch.Size([768])\n",
      "model.encoder.layers.3.fc1.weight: torch.Size([3072, 768])\n",
      "model.encoder.layers.3.fc1.bias: torch.Size([3072])\n",
      "model.encoder.layers.3.fc2.weight: torch.Size([768, 3072])\n",
      "model.encoder.layers.3.fc2.bias: torch.Size([768])\n",
      "model.encoder.layers.3.final_layer_norm.weight: torch.Size([768])\n",
      "model.encoder.layers.3.final_layer_norm.bias: torch.Size([768])\n",
      "model.encoder.layers.3.output_adapters.adapters.adapter1.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.encoder.layers.3.output_adapters.adapters.adapter1.adapter_down.0.bias: torch.Size([48])\n",
      "model.encoder.layers.3.output_adapters.adapters.adapter1.adapter_up.weight: torch.Size([768, 48])\n",
      "model.encoder.layers.3.output_adapters.adapters.adapter1.adapter_up.bias: torch.Size([768])\n",
      "model.encoder.layers.3.output_adapters.adapters.adapter2.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.encoder.layers.3.output_adapters.adapters.adapter2.adapter_down.0.bias: torch.Size([48])\n",
      "model.encoder.layers.3.output_adapters.adapters.adapter2.adapter_up.weight: torch.Size([768, 48])\n",
      "model.encoder.layers.3.output_adapters.adapters.adapter2.adapter_up.bias: torch.Size([768])\n",
      "model.encoder.layers.3.output_adapters.adapters.adapter3.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.encoder.layers.3.output_adapters.adapters.adapter3.adapter_down.0.bias: torch.Size([48])\n",
      "model.encoder.layers.3.output_adapters.adapters.adapter3.adapter_up.weight: torch.Size([768, 48])\n",
      "model.encoder.layers.3.output_adapters.adapters.adapter3.adapter_up.bias: torch.Size([768])\n",
      "model.encoder.layers.3.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.3.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.bias: torch.Size([768])\n",
      "model.encoder.layers.3.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.3.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.bias: torch.Size([768])\n",
      "model.encoder.layers.3.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.value.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.4.self_attn.k_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.4.self_attn.v_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.4.self_attn.q_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.4.self_attn.out_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.4.self_attn_layer_norm.weight: torch.Size([768])\n",
      "model.encoder.layers.4.self_attn_layer_norm.bias: torch.Size([768])\n",
      "model.encoder.layers.4.fc1.weight: torch.Size([3072, 768])\n",
      "model.encoder.layers.4.fc1.bias: torch.Size([3072])\n",
      "model.encoder.layers.4.fc2.weight: torch.Size([768, 3072])\n",
      "model.encoder.layers.4.fc2.bias: torch.Size([768])\n",
      "model.encoder.layers.4.final_layer_norm.weight: torch.Size([768])\n",
      "model.encoder.layers.4.final_layer_norm.bias: torch.Size([768])\n",
      "model.encoder.layers.4.output_adapters.adapters.adapter1.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.encoder.layers.4.output_adapters.adapters.adapter1.adapter_down.0.bias: torch.Size([48])\n",
      "model.encoder.layers.4.output_adapters.adapters.adapter1.adapter_up.weight: torch.Size([768, 48])\n",
      "model.encoder.layers.4.output_adapters.adapters.adapter1.adapter_up.bias: torch.Size([768])\n",
      "model.encoder.layers.4.output_adapters.adapters.adapter2.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.encoder.layers.4.output_adapters.adapters.adapter2.adapter_down.0.bias: torch.Size([48])\n",
      "model.encoder.layers.4.output_adapters.adapters.adapter2.adapter_up.weight: torch.Size([768, 48])\n",
      "model.encoder.layers.4.output_adapters.adapters.adapter2.adapter_up.bias: torch.Size([768])\n",
      "model.encoder.layers.4.output_adapters.adapters.adapter3.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.encoder.layers.4.output_adapters.adapters.adapter3.adapter_down.0.bias: torch.Size([48])\n",
      "model.encoder.layers.4.output_adapters.adapters.adapter3.adapter_up.weight: torch.Size([768, 48])\n",
      "model.encoder.layers.4.output_adapters.adapters.adapter3.adapter_up.bias: torch.Size([768])\n",
      "model.encoder.layers.4.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.4.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.bias: torch.Size([768])\n",
      "model.encoder.layers.4.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.4.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.bias: torch.Size([768])\n",
      "model.encoder.layers.4.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.value.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.5.self_attn.k_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.5.self_attn.v_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.5.self_attn.q_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.5.self_attn.out_proj.bias: torch.Size([768])\n",
      "model.encoder.layers.5.self_attn_layer_norm.weight: torch.Size([768])\n",
      "model.encoder.layers.5.self_attn_layer_norm.bias: torch.Size([768])\n",
      "model.encoder.layers.5.fc1.weight: torch.Size([3072, 768])\n",
      "model.encoder.layers.5.fc1.bias: torch.Size([3072])\n",
      "model.encoder.layers.5.fc2.weight: torch.Size([768, 3072])\n",
      "model.encoder.layers.5.fc2.bias: torch.Size([768])\n",
      "model.encoder.layers.5.final_layer_norm.weight: torch.Size([768])\n",
      "model.encoder.layers.5.final_layer_norm.bias: torch.Size([768])\n",
      "model.encoder.layers.5.output_adapters.adapters.adapter1.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.encoder.layers.5.output_adapters.adapters.adapter1.adapter_down.0.bias: torch.Size([48])\n",
      "model.encoder.layers.5.output_adapters.adapters.adapter1.adapter_up.weight: torch.Size([768, 48])\n",
      "model.encoder.layers.5.output_adapters.adapters.adapter1.adapter_up.bias: torch.Size([768])\n",
      "model.encoder.layers.5.output_adapters.adapters.adapter2.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.encoder.layers.5.output_adapters.adapters.adapter2.adapter_down.0.bias: torch.Size([48])\n",
      "model.encoder.layers.5.output_adapters.adapters.adapter2.adapter_up.weight: torch.Size([768, 48])\n",
      "model.encoder.layers.5.output_adapters.adapters.adapter2.adapter_up.bias: torch.Size([768])\n",
      "model.encoder.layers.5.output_adapters.adapters.adapter3.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.encoder.layers.5.output_adapters.adapters.adapter3.adapter_down.0.bias: torch.Size([48])\n",
      "model.encoder.layers.5.output_adapters.adapters.adapter3.adapter_up.weight: torch.Size([768, 48])\n",
      "model.encoder.layers.5.output_adapters.adapters.adapter3.adapter_up.bias: torch.Size([768])\n",
      "model.encoder.layers.5.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.5.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.bias: torch.Size([768])\n",
      "model.encoder.layers.5.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.weight: torch.Size([768, 768])\n",
      "model.encoder.layers.5.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.bias: torch.Size([768])\n",
      "model.encoder.layers.5.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.value.weight: torch.Size([768, 768])\n",
      "model.encoder.layernorm_embedding.weight: torch.Size([768])\n",
      "model.encoder.layernorm_embedding.bias: torch.Size([768])\n",
      "model.decoder.embed_positions.weight: torch.Size([1026, 768])\n",
      "model.decoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.0.self_attn.k_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.0.self_attn.v_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.0.self_attn.q_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.0.self_attn.out_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.0.self_attn_layer_norm.weight: torch.Size([768])\n",
      "model.decoder.layers.0.self_attn_layer_norm.bias: torch.Size([768])\n",
      "model.decoder.layers.0.encoder_attn.k_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.0.encoder_attn.k_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.0.encoder_attn.v_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.0.encoder_attn.v_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.0.encoder_attn.q_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.0.encoder_attn.q_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.0.encoder_attn.out_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.0.encoder_attn.out_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.0.encoder_attn_layer_norm.weight: torch.Size([768])\n",
      "model.decoder.layers.0.encoder_attn_layer_norm.bias: torch.Size([768])\n",
      "model.decoder.layers.0.fc1.weight: torch.Size([3072, 768])\n",
      "model.decoder.layers.0.fc1.bias: torch.Size([3072])\n",
      "model.decoder.layers.0.fc2.weight: torch.Size([768, 3072])\n",
      "model.decoder.layers.0.fc2.bias: torch.Size([768])\n",
      "model.decoder.layers.0.final_layer_norm.weight: torch.Size([768])\n",
      "model.decoder.layers.0.final_layer_norm.bias: torch.Size([768])\n",
      "model.decoder.layers.0.output_adapters.adapters.adapter1.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.decoder.layers.0.output_adapters.adapters.adapter1.adapter_down.0.bias: torch.Size([48])\n",
      "model.decoder.layers.0.output_adapters.adapters.adapter1.adapter_up.weight: torch.Size([768, 48])\n",
      "model.decoder.layers.0.output_adapters.adapters.adapter1.adapter_up.bias: torch.Size([768])\n",
      "model.decoder.layers.0.output_adapters.adapters.adapter2.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.decoder.layers.0.output_adapters.adapters.adapter2.adapter_down.0.bias: torch.Size([48])\n",
      "model.decoder.layers.0.output_adapters.adapters.adapter2.adapter_up.weight: torch.Size([768, 48])\n",
      "model.decoder.layers.0.output_adapters.adapters.adapter2.adapter_up.bias: torch.Size([768])\n",
      "model.decoder.layers.0.output_adapters.adapters.adapter3.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.decoder.layers.0.output_adapters.adapters.adapter3.adapter_down.0.bias: torch.Size([48])\n",
      "model.decoder.layers.0.output_adapters.adapters.adapter3.adapter_up.weight: torch.Size([768, 48])\n",
      "model.decoder.layers.0.output_adapters.adapters.adapter3.adapter_up.bias: torch.Size([768])\n",
      "model.decoder.layers.0.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.0.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.bias: torch.Size([768])\n",
      "model.decoder.layers.0.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.0.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.bias: torch.Size([768])\n",
      "model.decoder.layers.0.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.value.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.1.self_attn.k_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.1.self_attn.v_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.1.self_attn.q_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.1.self_attn.out_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.1.self_attn_layer_norm.weight: torch.Size([768])\n",
      "model.decoder.layers.1.self_attn_layer_norm.bias: torch.Size([768])\n",
      "model.decoder.layers.1.encoder_attn.k_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.1.encoder_attn.k_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.1.encoder_attn.v_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.1.encoder_attn.v_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.1.encoder_attn.q_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.1.encoder_attn.q_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.1.encoder_attn.out_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.1.encoder_attn.out_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.1.encoder_attn_layer_norm.weight: torch.Size([768])\n",
      "model.decoder.layers.1.encoder_attn_layer_norm.bias: torch.Size([768])\n",
      "model.decoder.layers.1.fc1.weight: torch.Size([3072, 768])\n",
      "model.decoder.layers.1.fc1.bias: torch.Size([3072])\n",
      "model.decoder.layers.1.fc2.weight: torch.Size([768, 3072])\n",
      "model.decoder.layers.1.fc2.bias: torch.Size([768])\n",
      "model.decoder.layers.1.final_layer_norm.weight: torch.Size([768])\n",
      "model.decoder.layers.1.final_layer_norm.bias: torch.Size([768])\n",
      "model.decoder.layers.1.output_adapters.adapters.adapter1.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.decoder.layers.1.output_adapters.adapters.adapter1.adapter_down.0.bias: torch.Size([48])\n",
      "model.decoder.layers.1.output_adapters.adapters.adapter1.adapter_up.weight: torch.Size([768, 48])\n",
      "model.decoder.layers.1.output_adapters.adapters.adapter1.adapter_up.bias: torch.Size([768])\n",
      "model.decoder.layers.1.output_adapters.adapters.adapter2.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.decoder.layers.1.output_adapters.adapters.adapter2.adapter_down.0.bias: torch.Size([48])\n",
      "model.decoder.layers.1.output_adapters.adapters.adapter2.adapter_up.weight: torch.Size([768, 48])\n",
      "model.decoder.layers.1.output_adapters.adapters.adapter2.adapter_up.bias: torch.Size([768])\n",
      "model.decoder.layers.1.output_adapters.adapters.adapter3.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.decoder.layers.1.output_adapters.adapters.adapter3.adapter_down.0.bias: torch.Size([48])\n",
      "model.decoder.layers.1.output_adapters.adapters.adapter3.adapter_up.weight: torch.Size([768, 48])\n",
      "model.decoder.layers.1.output_adapters.adapters.adapter3.adapter_up.bias: torch.Size([768])\n",
      "model.decoder.layers.1.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.1.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.bias: torch.Size([768])\n",
      "model.decoder.layers.1.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.1.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.bias: torch.Size([768])\n",
      "model.decoder.layers.1.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.value.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.2.self_attn.k_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.2.self_attn.v_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.2.self_attn.q_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.2.self_attn.out_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.2.self_attn_layer_norm.weight: torch.Size([768])\n",
      "model.decoder.layers.2.self_attn_layer_norm.bias: torch.Size([768])\n",
      "model.decoder.layers.2.encoder_attn.k_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.2.encoder_attn.k_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.2.encoder_attn.v_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.2.encoder_attn.v_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.2.encoder_attn.q_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.2.encoder_attn.q_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.2.encoder_attn.out_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.2.encoder_attn.out_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.2.encoder_attn_layer_norm.weight: torch.Size([768])\n",
      "model.decoder.layers.2.encoder_attn_layer_norm.bias: torch.Size([768])\n",
      "model.decoder.layers.2.fc1.weight: torch.Size([3072, 768])\n",
      "model.decoder.layers.2.fc1.bias: torch.Size([3072])\n",
      "model.decoder.layers.2.fc2.weight: torch.Size([768, 3072])\n",
      "model.decoder.layers.2.fc2.bias: torch.Size([768])\n",
      "model.decoder.layers.2.final_layer_norm.weight: torch.Size([768])\n",
      "model.decoder.layers.2.final_layer_norm.bias: torch.Size([768])\n",
      "model.decoder.layers.2.output_adapters.adapters.adapter1.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.decoder.layers.2.output_adapters.adapters.adapter1.adapter_down.0.bias: torch.Size([48])\n",
      "model.decoder.layers.2.output_adapters.adapters.adapter1.adapter_up.weight: torch.Size([768, 48])\n",
      "model.decoder.layers.2.output_adapters.adapters.adapter1.adapter_up.bias: torch.Size([768])\n",
      "model.decoder.layers.2.output_adapters.adapters.adapter2.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.decoder.layers.2.output_adapters.adapters.adapter2.adapter_down.0.bias: torch.Size([48])\n",
      "model.decoder.layers.2.output_adapters.adapters.adapter2.adapter_up.weight: torch.Size([768, 48])\n",
      "model.decoder.layers.2.output_adapters.adapters.adapter2.adapter_up.bias: torch.Size([768])\n",
      "model.decoder.layers.2.output_adapters.adapters.adapter3.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.decoder.layers.2.output_adapters.adapters.adapter3.adapter_down.0.bias: torch.Size([48])\n",
      "model.decoder.layers.2.output_adapters.adapters.adapter3.adapter_up.weight: torch.Size([768, 48])\n",
      "model.decoder.layers.2.output_adapters.adapters.adapter3.adapter_up.bias: torch.Size([768])\n",
      "model.decoder.layers.2.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.2.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.bias: torch.Size([768])\n",
      "model.decoder.layers.2.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.2.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.bias: torch.Size([768])\n",
      "model.decoder.layers.2.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.value.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.3.self_attn.k_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.3.self_attn.v_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.3.self_attn.q_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.3.self_attn.out_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.3.self_attn_layer_norm.weight: torch.Size([768])\n",
      "model.decoder.layers.3.self_attn_layer_norm.bias: torch.Size([768])\n",
      "model.decoder.layers.3.encoder_attn.k_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.3.encoder_attn.k_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.3.encoder_attn.v_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.3.encoder_attn.v_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.3.encoder_attn.q_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.3.encoder_attn.q_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.3.encoder_attn.out_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.3.encoder_attn.out_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.3.encoder_attn_layer_norm.weight: torch.Size([768])\n",
      "model.decoder.layers.3.encoder_attn_layer_norm.bias: torch.Size([768])\n",
      "model.decoder.layers.3.fc1.weight: torch.Size([3072, 768])\n",
      "model.decoder.layers.3.fc1.bias: torch.Size([3072])\n",
      "model.decoder.layers.3.fc2.weight: torch.Size([768, 3072])\n",
      "model.decoder.layers.3.fc2.bias: torch.Size([768])\n",
      "model.decoder.layers.3.final_layer_norm.weight: torch.Size([768])\n",
      "model.decoder.layers.3.final_layer_norm.bias: torch.Size([768])\n",
      "model.decoder.layers.3.output_adapters.adapters.adapter1.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.decoder.layers.3.output_adapters.adapters.adapter1.adapter_down.0.bias: torch.Size([48])\n",
      "model.decoder.layers.3.output_adapters.adapters.adapter1.adapter_up.weight: torch.Size([768, 48])\n",
      "model.decoder.layers.3.output_adapters.adapters.adapter1.adapter_up.bias: torch.Size([768])\n",
      "model.decoder.layers.3.output_adapters.adapters.adapter2.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.decoder.layers.3.output_adapters.adapters.adapter2.adapter_down.0.bias: torch.Size([48])\n",
      "model.decoder.layers.3.output_adapters.adapters.adapter2.adapter_up.weight: torch.Size([768, 48])\n",
      "model.decoder.layers.3.output_adapters.adapters.adapter2.adapter_up.bias: torch.Size([768])\n",
      "model.decoder.layers.3.output_adapters.adapters.adapter3.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.decoder.layers.3.output_adapters.adapters.adapter3.adapter_down.0.bias: torch.Size([48])\n",
      "model.decoder.layers.3.output_adapters.adapters.adapter3.adapter_up.weight: torch.Size([768, 48])\n",
      "model.decoder.layers.3.output_adapters.adapters.adapter3.adapter_up.bias: torch.Size([768])\n",
      "model.decoder.layers.3.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.3.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.bias: torch.Size([768])\n",
      "model.decoder.layers.3.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.3.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.bias: torch.Size([768])\n",
      "model.decoder.layers.3.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.value.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.4.self_attn.k_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.4.self_attn.v_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.4.self_attn.q_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.4.self_attn.out_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.4.self_attn_layer_norm.weight: torch.Size([768])\n",
      "model.decoder.layers.4.self_attn_layer_norm.bias: torch.Size([768])\n",
      "model.decoder.layers.4.encoder_attn.k_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.4.encoder_attn.k_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.4.encoder_attn.v_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.4.encoder_attn.v_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.4.encoder_attn.q_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.4.encoder_attn.q_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.4.encoder_attn.out_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.4.encoder_attn.out_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.4.encoder_attn_layer_norm.weight: torch.Size([768])\n",
      "model.decoder.layers.4.encoder_attn_layer_norm.bias: torch.Size([768])\n",
      "model.decoder.layers.4.fc1.weight: torch.Size([3072, 768])\n",
      "model.decoder.layers.4.fc1.bias: torch.Size([3072])\n",
      "model.decoder.layers.4.fc2.weight: torch.Size([768, 3072])\n",
      "model.decoder.layers.4.fc2.bias: torch.Size([768])\n",
      "model.decoder.layers.4.final_layer_norm.weight: torch.Size([768])\n",
      "model.decoder.layers.4.final_layer_norm.bias: torch.Size([768])\n",
      "model.decoder.layers.4.output_adapters.adapters.adapter1.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.decoder.layers.4.output_adapters.adapters.adapter1.adapter_down.0.bias: torch.Size([48])\n",
      "model.decoder.layers.4.output_adapters.adapters.adapter1.adapter_up.weight: torch.Size([768, 48])\n",
      "model.decoder.layers.4.output_adapters.adapters.adapter1.adapter_up.bias: torch.Size([768])\n",
      "model.decoder.layers.4.output_adapters.adapters.adapter2.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.decoder.layers.4.output_adapters.adapters.adapter2.adapter_down.0.bias: torch.Size([48])\n",
      "model.decoder.layers.4.output_adapters.adapters.adapter2.adapter_up.weight: torch.Size([768, 48])\n",
      "model.decoder.layers.4.output_adapters.adapters.adapter2.adapter_up.bias: torch.Size([768])\n",
      "model.decoder.layers.4.output_adapters.adapters.adapter3.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.decoder.layers.4.output_adapters.adapters.adapter3.adapter_down.0.bias: torch.Size([48])\n",
      "model.decoder.layers.4.output_adapters.adapters.adapter3.adapter_up.weight: torch.Size([768, 48])\n",
      "model.decoder.layers.4.output_adapters.adapters.adapter3.adapter_up.bias: torch.Size([768])\n",
      "model.decoder.layers.4.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.4.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.bias: torch.Size([768])\n",
      "model.decoder.layers.4.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.4.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.bias: torch.Size([768])\n",
      "model.decoder.layers.4.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.value.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.5.self_attn.k_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.5.self_attn.v_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.5.self_attn.q_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.5.self_attn.out_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.5.self_attn_layer_norm.weight: torch.Size([768])\n",
      "model.decoder.layers.5.self_attn_layer_norm.bias: torch.Size([768])\n",
      "model.decoder.layers.5.encoder_attn.k_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.5.encoder_attn.k_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.5.encoder_attn.v_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.5.encoder_attn.v_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.5.encoder_attn.q_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.5.encoder_attn.q_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.5.encoder_attn.out_proj.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.5.encoder_attn.out_proj.bias: torch.Size([768])\n",
      "model.decoder.layers.5.encoder_attn_layer_norm.weight: torch.Size([768])\n",
      "model.decoder.layers.5.encoder_attn_layer_norm.bias: torch.Size([768])\n",
      "model.decoder.layers.5.fc1.weight: torch.Size([3072, 768])\n",
      "model.decoder.layers.5.fc1.bias: torch.Size([3072])\n",
      "model.decoder.layers.5.fc2.weight: torch.Size([768, 3072])\n",
      "model.decoder.layers.5.fc2.bias: torch.Size([768])\n",
      "model.decoder.layers.5.final_layer_norm.weight: torch.Size([768])\n",
      "model.decoder.layers.5.final_layer_norm.bias: torch.Size([768])\n",
      "model.decoder.layers.5.output_adapters.adapters.adapter1.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.decoder.layers.5.output_adapters.adapters.adapter1.adapter_down.0.bias: torch.Size([48])\n",
      "model.decoder.layers.5.output_adapters.adapters.adapter1.adapter_up.weight: torch.Size([768, 48])\n",
      "model.decoder.layers.5.output_adapters.adapters.adapter1.adapter_up.bias: torch.Size([768])\n",
      "model.decoder.layers.5.output_adapters.adapters.adapter2.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.decoder.layers.5.output_adapters.adapters.adapter2.adapter_down.0.bias: torch.Size([48])\n",
      "model.decoder.layers.5.output_adapters.adapters.adapter2.adapter_up.weight: torch.Size([768, 48])\n",
      "model.decoder.layers.5.output_adapters.adapters.adapter2.adapter_up.bias: torch.Size([768])\n",
      "model.decoder.layers.5.output_adapters.adapters.adapter3.adapter_down.0.weight: torch.Size([48, 768])\n",
      "model.decoder.layers.5.output_adapters.adapters.adapter3.adapter_down.0.bias: torch.Size([48])\n",
      "model.decoder.layers.5.output_adapters.adapters.adapter3.adapter_up.weight: torch.Size([768, 48])\n",
      "model.decoder.layers.5.output_adapters.adapters.adapter3.adapter_up.bias: torch.Size([768])\n",
      "model.decoder.layers.5.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.5.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.query.bias: torch.Size([768])\n",
      "model.decoder.layers.5.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.weight: torch.Size([768, 768])\n",
      "model.decoder.layers.5.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.key.bias: torch.Size([768])\n",
      "model.decoder.layers.5.output_adapters.adapter_fusion_layer.adapter1,adapter2,adapter3.value.weight: torch.Size([768, 768])\n",
      "model.decoder.layernorm_embedding.weight: torch.Size([768])\n",
      "model.decoder.layernorm_embedding.bias: torch.Size([768])\n",
      "Total number of trainable parameters: 163356096\n",
      "\n",
      "Untrainable Parameters:\n",
      "Total number of untrainable parameters: 0\n"
     ]
    }
   ],
   "source": [
    "def print_parameters(model):\n",
    "    trainable_params = {name: param for name, param in model.named_parameters() if param.requires_grad}\n",
    "    untrainable_params = {name: param for name, param in model.named_parameters() if not param.requires_grad}\n",
    "\n",
    "    print(\"Trainable Parameters:\")\n",
    "    total_trainable_params = 0\n",
    "    for name, param in trainable_params.items():\n",
    "        print(f\"{name}: {param.size()}\")\n",
    "        total_trainable_params += param.numel()\n",
    "    print(f\"Total number of trainable parameters: {total_trainable_params}\")\n",
    "\n",
    "    print(\"\\nUntrainable Parameters:\")\n",
    "    total_untrainable_params = 0\n",
    "    for name, param in untrainable_params.items():\n",
    "        print(f\"{name}: {param.size()}\")\n",
    "        total_untrainable_params += param.numel()\n",
    "    print(f\"Total number of untrainable parameters: {total_untrainable_params}\")\n",
    "\n",
    "# Assuming your model instance is named `model`\n",
    "print_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_path = \"/opt/dlami/nvme/\"\n",
    "\n",
    "# train_df = pd.read_csv(data_path + 'train.csv', usecols = ['input_text', 'target_text'])\n",
    "# val_df = pd.read_csv(data_path + 'val.csv', usecols = ['input_text', 'target_text'])\n",
    "# test_df = pd.read_csv(data_path + 'test.csv', usecols = ['input_text', 'target_text'])\n",
    "\n",
    "\n",
    "df = pd.read_excel(\"/opt/dlami/nvme/plos_all.xlsx\")\n",
    "\n",
    "def create_dataframe(df, split):\n",
    "    selected_df = df[df[\"Split\"] == split][[\"Abstract\", \"Summary\"]].rename(columns={\"Abstract\": \"input_text\", \"Summary\": \"target_text\"})\n",
    "    return selected_df\n",
    "\n",
    "train_df, test_df, val_df = create_dataframe(df, \"train\"), create_dataframe(df, \"test\"), create_dataframe(df, \"val\")\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = Dataset.from_dict(train_df), Dataset.from_dict(val_df), Dataset.from_dict(test_df)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset,\n",
    "    \"val\": val_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Kidney function depends on the nephron , which comprises a blood filter , a tubule that is subdivided into functionally distinct segments , and a collecting duct . How these regions arise during development is poorly understood . The zebrafish pronephros consists of two linear nephrons that develop from the intermediate mesoderm along the length of the trunk . Here we show that , contrary to current dogma , these nephrons possess multiple proximal and distal tubule domains that resemble the organization of the mammalian nephron . We examined whether pronephric segmentation is mediated by retinoic acid ( RA ) and the caudal ( cdx ) transcription factors , which are known regulators of segmental identity during development . Inhibition of RA signaling resulted in a loss of the proximal segments and an expansion of the distal segments , while exogenous RA treatment induced proximal segment fates at the expense of distal fates . Loss of cdx function caused abrogation of distal segments , a posterior shift in the position of the pronephros , and alterations in the expression boundaries of raldh2 and cyp26a1 , which encode enzymes that synthesize and degrade RA , respectively . These results suggest that the cdx genes act to localize the activity of RA along the axis , thereby determining where the pronephros forms . Consistent with this , the pronephric-positioning defect and the loss of distal tubule fate were rescued in embryos doubly-deficient for cdx and RA . These findings reveal a novel link between the RA and cdx pathways and provide a model for how pronephric nephrons are segmented and positioned along the embryonic axis .',\n",
       " \"In the kidney , structures known as nephrons are responsible for collecting metabolic waste . Nephrons are composed of a blood filter ( glomerulus ) followed by a series of specialized tubule regions , or segments , which recover solutes such as salts , and finally terminate with a collecting duct . The genetic mechanisms that establish nephron segmentation in mammals have been a challenge to study because of the kidney's complex organogenesis . The zebrafish embryonic kidney ( pronephros ) contains two nephrons , previously thought to consist of a glomerulus , short tubule , and long stretch of duct . In this study , we have redefined the anatomy of the zebrafish pronephros and shown that the duct is actually subdivided into distinct tubule segments that are analogous to the proximal and distal segments found in mammalian nephrons . Next , we used the zebrafish pronephros to investigate how nephron segmentation occurs . We found that retinoic acid ( RA ) induces proximal pronephros segments and represses distal segment fates . Further , we found that the caudal ( cdx ) transcription factors direct the anteroposterior location of pronephric progenitors by regulating the site of RA production . Taken together , these results reveal that a cdx-RA pathway plays a key role in both establishing where the pronephros forms along the embryonic axis as well as its segmentation pattern .\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['input_text'][0], dataset['train']['target_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/24773 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 24773/24773 [00:29<00:00, 843.00 examples/s]\n",
      "Map: 100%|██████████| 1376/1376 [00:01<00:00, 822.20 examples/s]\n",
      "Map: 100%|██████████| 1376/1376 [00:01<00:00, 848.19 examples/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "max_length = 1024 \n",
    "\n",
    "def process_data(batch, tokenizer):\n",
    "    inputs = tokenizer(batch[\"input_text\"], padding=\"max_length\", max_length=max_length, truncation=True)\n",
    "    outputs = tokenizer(batch[\"target_text\"], padding=\"max_length\", max_length=max_length, truncation=True)\n",
    "    batch[\"input_ids\"] = inputs.input_ids\n",
    "    batch[\"attention_mask\"] = inputs.attention_mask\n",
    "    labels = np.array([[-100 if token == tokenizer.pad_token_id else token for token in label]\n",
    "                       for label in outputs.input_ids], dtype=np.int64)\n",
    "    batch[\"labels\"] = torch.tensor(labels)\n",
    "    return batch\n",
    "\n",
    "dataset = dataset.map(lambda batch: process_data(batch, tokenizer), batched=True, batch_size=batch_size, remove_columns=['input_text', 'target_text'])\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='7740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   5/7740 00:17 < 12:46:59, 0.17 it/s, Epoch 0.01/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 38\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m     29\u001b[0m trainer \u001b[38;5;241m=\u001b[39m AdapterTrainer(\n\u001b[1;32m     30\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     31\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator\n\u001b[1;32m     36\u001b[0m )\n\u001b[0;32m---> 38\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mmodel\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2216\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2216\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2219\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2220\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2221\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2222\u001b[0m ):\n\u001b[1;32m   2223\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2224\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:3238\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3238\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3240\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3241\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:3264\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3263\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3264\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3265\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3266\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/utils/operations.py:822\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 822\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/utils/operations.py:810\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/amp/autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/utils/operations.py:822\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 822\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/utils/operations.py:810\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/amp/autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/adapters/src/adapters/models/bart/adapter_model.py:86\u001b[0m, in \u001b[0;36mBartAdapterModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, past_key_values, head, output_adapter_gating_scores, output_adapter_fusion_attentions, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_positions\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_positions\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m     84\u001b[0m     use_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m outputs, context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_adapter_gating_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_adapter_gating_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_adapter_fusion_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_adapter_fusion_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43madapter_input_parallelized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madapter_input_parallelized\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# required e.g. for prompt tuning in all models\u001b[39;00m\n\u001b[1;32m    108\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m context\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/adapters/src/adapters/context.py:116\u001b[0m, in \u001b[0;36mForwardContext.wrap.<locals>.wrapper_func\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m output_context \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_context\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    113\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    114\u001b[0m     k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_attributes\n\u001b[1;32m    115\u001b[0m }\n\u001b[0;32m--> 116\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# append output attributes\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/adapters/src/adapters/model_mixin.py:1276\u001b[0m, in \u001b[0;36mModelBaseAdaptersMixin.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;129m@ForwardContext\u001b[39m\u001b[38;5;241m.\u001b[39mwrap\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1610\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1607\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1610\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;66;03m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001b[39;00m\n\u001b[1;32m   1620\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1216\u001b[0m, in \u001b[0;36mBartEncoder.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1208\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1209\u001b[0m             encoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1210\u001b[0m             hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             output_attentions,\n\u001b[1;32m   1214\u001b[0m         )\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1216\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1223\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/adapters/src/adapters/models/bart/modeling_bart.py:430\u001b[0m, in \u001b[0;36mBartEncoderLayerWithAdapters.forward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    428\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(hidden_states)\n\u001b[1;32m    429\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m--> 430\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_adapters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_layer_norm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hidden_states\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16 \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    433\u001b[0m     torch\u001b[38;5;241m.\u001b[39misinf(hidden_states)\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(hidden_states)\u001b[38;5;241m.\u001b[39many()\n\u001b[1;32m    434\u001b[0m ):\n\u001b[1;32m    435\u001b[0m     clamp_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfinfo(hidden_states\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mmax \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1000\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/adapters/src/adapters/methods/bottleneck.py:390\u001b[0m, in \u001b[0;36mBottleneckLayer.forward\u001b[0;34m(self, hidden_states, residual_input, layer_norm)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states, residual_input, layer_norm):\n\u001b[1;32m    380\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through the adapter layer.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m        torch.Tensor: Output hidden states of the adapter layer.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbottleneck_layer_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_norm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/adapters/src/adapters/methods/bottleneck.py:366\u001b[0m, in \u001b[0;36mBottleneckLayer.bottleneck_layer_forward\u001b[0;34m(self, hidden_states, residual_input, layer_norm)\u001b[0m\n\u001b[1;32m    363\u001b[0m input_hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    365\u001b[0m state \u001b[38;5;241m=\u001b[39m BottleneckState(hidden_states, residual_input, residual_input, layer_norm)\n\u001b[0;32m--> 366\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose\u001b[49m\u001b[43m(\u001b[49m\u001b[43madapter_setup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m hidden_states, residual_input, _, _, _, last \u001b[38;5;241m=\u001b[39m state\n\u001b[1;32m    369\u001b[0m last_adapter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapters[last]\n",
      "File \u001b[0;32m~/adapters/src/adapters/methods/adapter_layer_base.py:479\u001b[0m, in \u001b[0;36mComposableAdapterLayerBase.compose\u001b[0;34m(self, adapter_setup, state)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(adapter_setup, AdapterCompositionBlock):\n\u001b[1;32m    478\u001b[0m     composition_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_compose_func(\u001b[38;5;28mtype\u001b[39m(adapter_setup))\n\u001b[0;32m--> 479\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[43mcomposition_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43madapter_setup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m adapter_setup \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapter_modules:\n\u001b[1;32m    481\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_single(adapter_setup, state, lvl\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/adapters/src/adapters/methods/adapter_layer_base.py:310\u001b[0m, in \u001b[0;36mComposableAdapterLayerBase.compose_stack\u001b[0;34m(self, adapter_setup, state, lvl)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_composition_valid(adapter_setup, adapter_stack_layer, lvl)\n\u001b[1;32m    309\u001b[0m     composition_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_compose_func(\u001b[38;5;28mtype\u001b[39m(adapter_stack_layer))\n\u001b[0;32m--> 310\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[43mcomposition_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43madapter_stack_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlvl\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m adapter_stack_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapter_modules:\n\u001b[1;32m    312\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_block(adapter_stack_layer, state)\n",
      "File \u001b[0;32m~/adapters/src/adapters/methods/bottleneck.py:277\u001b[0m, in \u001b[0;36mBottleneckLayer.compose_fuse\u001b[0;34m(self, adapter_setup, state, lvl)\u001b[0m\n\u001b[1;32m    275\u001b[0m     children_states\u001b[38;5;241m.\u001b[39mappend(child_state)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapter_modules:\n\u001b[0;32m--> 277\u001b[0m     child_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlvl\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m     children_states\u001b[38;5;241m.\u001b[39mappend(child_state)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/adapters/src/adapters/methods/bottleneck.py:244\u001b[0m, in \u001b[0;36mBottleneckLayer.compose_single\u001b[0;34m(self, adapter_setup, state, lvl)\u001b[0m\n\u001b[1;32m    242\u001b[0m adapter_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapters[adapter_setup]\n\u001b[1;32m    243\u001b[0m context \u001b[38;5;241m=\u001b[39m ForwardContext\u001b[38;5;241m.\u001b[39mget_context()\n\u001b[0;32m--> 244\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43madapter_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresidual_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madapter_residual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gating\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_adapter_gating_scores\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m hidden_states, up \u001b[38;5;241m=\u001b[39m layer_output[\u001b[38;5;241m0\u001b[39m], layer_output[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_gating_score(adapter_setup, layer_output[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/adapters/src/adapters/methods/modeling.py:196\u001b[0m, in \u001b[0;36mAdapter.forward\u001b[0;34m(self, x, residual_input, output_gating)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# if residual should be applied after layer norm, apply it here\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapter_residual_before_ln:\n\u001b[0;32m--> 196\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mresidual_input\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_gating \u001b[38;5;129;01mand\u001b[39;00m output_gating:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output, down, up, gate\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/fx/traceback.py:67\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m traceback\u001b[38;5;241m.\u001b[39mformat_list(\u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m/usr/lib/python3.10/traceback.py:227\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m--> 227\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[0;32m/usr/lib/python3.10/traceback.py:379\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    376\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[1;32m    377\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals))\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[0;32m--> 379\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[0;32m/usr/lib/python3.10/linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"/opt/dlami/nvme/no_fusion_layer/fine_tuned\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    per_device_train_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    load_best_model_at_end=True,\n",
    "    remove_unused_columns=True,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    num_train_epochs=10,\n",
    "    gradient_accumulation_steps=4,\n",
    "    eval_accumulation_steps=4,\n",
    "    learning_rate=2e-5,\n",
    "    bf16=True,\n",
    "    bf16_full_eval=True,\n",
    "    optim=\"adamw_bnb_8bit\",\n",
    "    seed=42,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Set Data Collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "# Train model\n",
    "trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['val'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trained_model = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/1376 [00:00<?, ?it/s]There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n",
      "Testing:   0%|          | 3/1376 [00:00<01:02, 22.04it/s]There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n",
      "Testing:   0%|          | 6/1376 [00:00<01:05, 20.94it/s]There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n",
      "Testing:   1%|          | 9/1376 [00:00<01:05, 20.86it/s]There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n",
      "Testing:   1%|          | 12/1376 [00:00<01:05, 20.73it/s]There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n",
      "Testing:   1%|          | 15/1376 [00:00<01:05, 20.71it/s]There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n",
      "Testing:   1%|▏         | 18/1376 [00:00<01:06, 20.45it/s]There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n",
      "Testing:   2%|▏         | 21/1376 [00:01<01:07, 20.20it/s]There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n",
      "Testing:   2%|▏         | 24/1376 [00:01<01:06, 20.20it/s]There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n",
      "Testing:   2%|▏         | 27/1376 [00:01<01:06, 20.36it/s]There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n",
      "Testing:   2%|▏         | 30/1376 [00:01<01:05, 20.43it/s]\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, tokenizer, max_length, test_dataset, num_samples=30):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    model.to(device)  # Ensure the model is on the correct device\n",
    "\n",
    "    decoded_preds = []\n",
    "    for i, batch in enumerate(tqdm(test_dataset, desc=\"Testing\")):  # Use tqdm to wrap the dataset\n",
    "        if i >= num_samples:  # Stop after processing num_samples batches\n",
    "            break\n",
    "        input_ids = batch[\"input_ids\"].clone().detach().unsqueeze(0).to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].clone().detach().unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():  \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, max_length=512, \n",
    "                            num_beams=2, length_penalty=2, no_repeat_ngram_size=3, early_stopping=True)\n",
    "            predicted_ids = torch.argmax(outputs.logits, dim=-1)\n",
    "        \n",
    "        output = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)\n",
    "        decoded_preds.append(output)\n",
    "    return decoded_preds\n",
    "\n",
    "# Set the device (e.g., \"cuda\" or \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_preds = test_model(model, tokenizer, max_length, dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infal epidemics of influenza virus result in approximately36, 000 deaths annually in the United States. Current vaccines against influenza virus elicit an antibody response specific for the envelope glycoproteins. However, high mutation rates result in the emergence of new viral serotypes, which elude neutralization by preexisting antibodies. T lymphocytes have been reported to be capable of mediating heterosubtypic protection through recognition of internal, more conserved, influenza virus proteins. Here, we demonstrate using a recombinant influenza virus expressing the epitMV GP33-41 epitope that influenza virus-specific antibodies8+ cells cells and virus-specific non-neutralizing antibodies each are relatively ineffective at conferring heterosubtypic protection immunity alone. However, when combined virus-specific CD8+ cells and non-neutralizing antibodies cooperatively elicit robust protective immunity, synergistic improvement in protective immunity is dependent, at least in part, on alveolar macrophages and/or other lung phagocytes. Overall, our studies suggest that an influenza vaccine capable of eliciting both CD8+ T cells and antibodies specific for highly conserved influenza proteins may be able to provide heterosubtypic protection in humans, and act as the basis for a potential “universal” vaccine... leaders leaders leaders leaders leaders leaders will leaders will party party leaders leaders leaders leaders leaders party leaders leaders leaders leaders leaders leaders�� party party party party��������� party����� party—��������� partythat� Minneapolis Minneapolis���� Minneapolis� Minneapolis Minneapolis���that��������� party party Minneapolis,, Minneapolis Minneapolis�——— Minneapolis�,,,, Kansas, Kansas Minneapolis Minneapolis Minneapolis Minneapolis,,,, Minneapolis� Minneapolis Minneapolis Kansas Minneapolis Minneapolis,,, Kansas Kansas Kansas�,,,, Minneapolis Minneapolis,, Minneapolis Minneapolis, Minneapolis,,, Minneapolis�� Kansas,,,�,,,,,,�,,,�������,,,,,���,,,����������������� Minneapolis Minneapolis Minneapolis��� Minneapolis Minneapolis�� Minneapolis Minneapolis Minneapolis Minneapolis� Minneapolis Kansas Minneapolis Minneapolis�,,, Minneapolis Minneapolis,, Minneapolis,, Minneapolis Minneapolis Minneapolis Minneapolis Minneapolis Minneapolis Minneapolis, Minneapolis Minneapolis Minneapolis.\"���.\".\"�.\"� lions lions.\".\".\".\".\"�.\"��.\".\".\".\".\".\".\"�\".\"���\"\"\" lions������.\"� Kansas lions����.\".\" lions lions\"\"\"\"\" lions Minneapolis.\"� lions Minneapolis, Kansas\"\" Minneapolis��,,, Kansas lions Kansas Kansas Kansas Kansas� lions lions Kansas Kansas Kansas lions���� Kansas.\" Kansas lions Kansas Kansas.\" Kansas.\" lions Minneapolis\".\"�.\"\"\".\".\".\"�.\".\".\"�� Kansas.\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\" Minneapolis.\".\".\".\".\".\".\".\" Minneapolis.\".\".\".\".\".\"�.\"��������������.\"������������.\"��.\"������������.\"��.\"� Kansas�������� college��� college���������� college������������������������� college���\n",
      " migrationeprosy is a public health problem in Brazil with new case incidence exceeding the Health Organization ( WHO ) goals in endemic clusters throughout the country. Migration can facilitate movement of disease between endemic and non-endemic areas, and has been considered a possible factor in continued leprosy incidence in Brazil. a study was conducted to investigate migration as a risk factor for leprosy.  study had three aims: ( 1 ) examine past five year migration as a risk factor for leprosy, ( 2 ) describe and compare geographic and temporal patterns of migration among past 5-year migrants with leprosy and a control group, and ( 3 ) examine social determinants of health associated with leprosy among past 5-year migrants. study implemented a matched case-control design and analysis comparing individuals newly diagnosed with leprosy and n =�= 340 ) and a clinically unapparent control group ( n = 340 ) without clinical signs of leprosy, matched for age, sex and location in four endemic municipalities in the state of Maranhão, northeastern Brazil. s exact test was used to conduct bivariate analyses. a multivariate logistic regression analysis was employed to control for possible confounding variables. Pastighty cases ( 23. 5% ) migrated 5 yearsyears prior to diagnosis, and 55 controls ( 16. 2% ) migrated 5-years prior to the corresponding case diagnosis. Past 5 year migration was found to be associated with leprosy ( odds: 1. 59; 95% CI 1. 07–2. 38; p = 0. 02 ), and remained significantly associated with leprosy after controlling for leprosy contact in the family, household, and family/household contact. Poverty, as well as leprosy contact in the family, household and other leprosy contact, was associated with leprosy among past 5-year migrants in the bivariate analysis. Alcohol consumption was also associated with leprosy, a relevant risk factor in susceptibility to infection that should be explored in future research. findings provide insight into patterns of migration to localize focused control efforts in endemic areas with high population mobility.king�� and and�… leaders………………………………………………………………………………………………………………………………………….\"……….\"�.\"�,,,,,�,,,,,, Minneapolis,………��� Minneapolis Minneapolis……�,, Kansas�������,,, Omaha��,,,,, Omaha�,,,,����,�,��,,,,,,, Minneapolis��,,,,������…����������…………………………… party party……………………………………….\".\".\".\"…………………………………………………………………………………����…������…�����������……�……���…�…��������”��…………………………………………………………………………………………………�…… bo����………\n",
      "Leishmaniasis is caused from infection with the protozoan parasite Leishmania, is of a wide spectrum of clinical manifestations, from healing cutaneous lesions to fatal visceral infections. a particularly severe form of cutaneous leishmaniasis, termed mucosal leishmaniasis, exhibits decreased levels-10 levels and an exaggerated inflammatory response that perpetuates the disease. Using a mouse model of leishmaniasis, we investigated what cytokines contribute to increased pathology when the-10-mediated regulation is absent. Usingishmania major infected mice57BL/6 mice lacking the-10 expression developed larger lesions than controls, but fewer parasites. Both interN-γ and IL-17 levels were substantially elevated in mice lacking the capacity to respond to IL-10. IFN-γ promoted an increased infiltration of monocytes, while IL-17 contributed to an increase in neutrophils. Surprisingly, however, we found that blockingN-γ did not contribute to increased pathology, but instead regulated the IL-17 response. Thus, blocking IFN-γ led to a significant increase in the-17, neutrophils and disease. Similarly, the production of IL-17 by cells from leishmaniasis patients was also regulated by both-10 and IFN-γ. Additional studies found that the IL-1 receptor was required for both the IL-17 response and increased pathology., we propose that regulating the-17, possibly by downregulating the-1β, may be a useful approach for controlling immunopathology in leishmaniasis.:!: party party party party party party party……………………………………………………—thatthatthatthat Dallas Dallas Dallas——————thatthatthatthatthatthat Dallas————,,,,,�,,,,,,, Dallas Dallas Kansas�,,,,,,,,,,,,,,,,�� Kansas,,,,,,,,,,,,,,,,,,,,,,,,,,��,,,,,,,�,���,,,,����,,,,,,,����,,,,,, Sacramento, Sacramento,,,,,,,��,,,,,,,, Omaha Omaha,,,,,\"\"��\"�.\"\"�\"��.\"\"\".\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"�\"\"\" Omaha Kansas Omaha\" Omaha Omaha� Omaha\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\",\"\"\"\" Omaha\",,\"\"\"\" Omaha Omaha Omaha,\" Omaha\"\",\"\"\"\"\" Omaha\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"�\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\".\".\"\".\"\"\"\"\"\".\"\"\"\"\"\"\"\"\"\"������\"�\"\"\"\"\"\"���\"\"\"\"\"\"\"�\"\"\"\"����������\"������ bo���������� bo����������own����������������own.\"�own.\"own�.\".\".\"��.\"��ownownownown��own��own��own city������ college�\n",
      " evolutionary evolutionaryability of predictability of evolution is a central question in evolutionary biology and is often addressed in experimental evolution studies. Here, we use how genetically heterogeneous natural systems acquire the same molecular changes to address how genomic background affects adaptation in natural populations. We particular, we take advantage of independently formed neo-sex chromosomes in therosophila species that have evolved dosage compensation by co-opting the dosage-compensation male-specific lethal ( MSL ) complex. study the mutational paths that have led to the acquisition of hundreds of novel binding sites for the MSL complex in different species. complex recognizes a conserved 21-bp GA-rich sequence motif that is enriched on the X chromosome, and newly formed X chromosomes recruit the MSL complex by de novo acquisition of this binding motif. We identify recently formed sex chromosomes in the fruit. melanica and the. robusta species groups by genome sequencing and generate genomic occupancy maps of the MSL complex to infer the location of novel binding sites. find that diverse mutational paths were utilized in each species to evolve hundreds of de novo binding motifs along the neo-X, including expansions of microsatellites and transposable element insert TE ) insertions., the propensity to utilize a particular mutational path differs between independently formed X chromosomes and appears to be contingent on genomic properties of that species, such as simple repeat or TE density. establishes the genomic�genomic environment” as an important determinant in predicting the outcome of evolutionary adaptations. the... party party party party party party party party party party party party party party party party party party…………………………………………— party party party party–– Dallas—————————thatthatthatthatthat—————,,—���,,—,,, Kansas Dallas Kansas��,,,, Minneapolis,,�,,,,,, Kansas�� Kansas,,,,,,,,,,,,,,,�,�,, Minneapolis,,,,, Minneapolis�,,,,, Minneapolis, Minneapolis Minneapolis Minneapolis���,, Minneapolis� Mald� Minneapolis Minneapolis Minneapolis party Minneapolis,,, Mald Minneapolis� Minneapolis party party party,, Minneapolis Sacramentothat party party party, party,,, Minneapolis Minneapolis,,,,,,,, Minneapolis Minneapolis Minneapolis,,,,��������������.\"�������.\"��.\"�.\"��������\"����������� Kansas�������,��������������,������,,,,�� Kansas Kansas,���,,,��.\"���.\".\".\".\".\".\".\".\".\".\"�\"��.\"�.\"\"\"\"�.\".\".\".\"���.\"�.\"�.\".\".\".\".\".\".\".\".\".\".\"�.\".\".\"\".\".\".\"�.\".\".\".\".\".\".\".\".\".\".\".\".\".\"���������������������������������������������������������������������������������� bo������������ bo��������������������� city\n",
      "Prions are self-propagating conformations of proteins that can cause heritable phenotypic traits. Most yeast prions contain glutamine ( Q ) /asparagine ( N ) -rich domains that facilitate the accumulation of the protein into amyloid-like aggregates. [fficient transmission of these infectious aggregates to daughter cells requires that chaperones, including Hsp104 and Sis1, continually sever the aggregates into smaller,�seeds..� we previously identified 11 proteins with Q/N-rich domains that, when overproduced, facilitate the de novo aggregation of the Sup35 protein into the [PSI +] prion state. Here, we show that overexpression of many of the same 11 Q/N-rich proteins can also destabilize pre-existing [PSI+] or [URE3] prions. explore in detail the events leading to the loss ( curing ) of [PSI+] by the overexpression of one of these proteins, the Q/N-rich domain of Pin4, which causes Sup35 aggregates to increase in size and decrease in transmissibility to daughter cells. show that the Pin4 Q/N-rich domain sequesters hsp104 and Sis1 chaperones away from the diffuse cytoplasmic pool., a mechanism by which heterologous Q/N-rich proteins impair prion propagation appears to be the loss of cytoplasmic Hsp104 and Sis1 available to sever [PSI+].... party party party party party party party party party…………………………………………thatthat…… Mald��……——…………that Kansas—��—————…— Kansas���—�—�� Kansas Kansas Kansas Kansas���,,��������,,, Kansas����,,,,,,,,,�,,,,���,,�,,,,,���,,,��,�� Minneapolis���,,�����, Minneapolis,,,,, Minneapolis Minneapolis��,,,,, Minneapolis�� Minneapolis,,,,,,, Minneapolis�,,,,,,,, Omaha Omaha,,,,,,,����\"������.\".\"���.\"��.\"��\".\"��\"\"\"��\",\"�������,� Kansas Kansas�����,,,��\",\",\"�\"�\"��,,,,\"���,,,,�� Kansas Kansas,�\"�,,,,��\"\"��\"\",,,,\",\"\"\"\"�\"\"�\"\"\"\"�\"��.\".\".\".\".\"\".\".\".\"�\".\".\".\".\"�.\"\"\".\"\"��\"\"\"\".\"\"���.\".\".\".\".\"\".\".\".\"���.\"����������������.\"���������������.\"����������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������\n",
      " imprint imprint of the questions raised by the discovery of imprinting have been answered, we have not yet accounted for tissue- or stage-specific imprinting. the imprintcnq1 imprinted domain exhibits complex tissue-specific expression patterns co-existing with a domain-wide cis-acting control element. Transcription of the paternally expressed antisense non-coding RNA Kcnq1ot1 silences some neighboring genes in the embryo, while others are unaffected. Kcnq1 is imprinted in early cardiac development but becomes biallelic after midgestation. To explore this phenomenon and the role of Kcnq1ot1, we used allele-specific assays and chromosome conformational studies in wild-type mice and mice with a premature termination mutation for Kcnq1ot1. We show that imprintcnq1 imprinting in early heart is established and maintained independently of thecnq1ot1 expression, thus excluding a role for Kcnq1ot1 in repressing Kcnq1, even while silencing other genes in the domain. the exact timing of the mono- to biallelic transition is strain-dependent, with the cAST/EiJ allele becoming activated earlier and acquiring higher levels than the C57BL/6J allele. Unexpectedly, thecnq1ot1 itself also switches to biallelic expression specifically in the heart, suggesting that tissue-specific loss of imprinting may be common during embryogenesis. maternal kcnq1ot1 transcript is shorter than the paternal ncRNA, and its activation depends on an alternative transcriptional start site that bypasses the maternally methylated promoter. Production of Kcnq1ot1 on the maternal chromosome does not silence thedkn1c. find that in later developmental stages, however, thecnq1ot1 has a role in modulating Kcnq1 levels, since its absence leads to overexpression of Kcnq1, an event accompanied by an aberrant three-dimensional structure of the chromatin., our studies reveal regulatory mechanisms within the kcnq1 imprinted domain that operate exclusively in the heart on thecnq1, a gene crucial for heart development and function. also uncover a novel mechanism by which an antisense non-coding RNA affects transcription through regulating chromatin flexibility and access to enhancers............ bo bo of by bo,,..\".\",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,that��,�,,,.\",,,,,�,,,,,.\",,��,���� Heights.\".\".\".\".\".\".\"��,���.\".\"��,��-\"���������������,,���� lions lions lions�� lions lions� lions lions� lions lions� bo bo lions bo bo boedge bo lionsedgeedge editorial�edgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedgeedge���edge�edgeedgeedgeedge editorial editorial�� editorial city city\n",
      " mutationsifying the distribution of fitness effects among newly arising mutations in the human genome is key to resolving important debates in medical and evolutionary genetics. Here, we present a method for inferring this distribution using single Nucleotide Polymorphism ( SNP ) data from a population with non-stationary demographic history ( such as that of modern humans ). Application of our method to 47, 576 coding SNPs found by direct resequencing of 11, 404 protein coding-genes in 35 individuals ( 20 European Americans and 15 African Americans ) allows us to assess the relative contribution of demographic and selective effects to patterning amino acid variation in the human genome. We find evidence of an ancient population expansion in the sample with African ancestry and a relatively recent bottleneck in the sample with European ancestry. After accounting for these demographic effects, we find strong evidence for great variability in the selective effects of new amino acid replacing mutations. both populations, the patterns of variation are consistent with a leptokurtic distribution of selection coefficients ( e. g., gamma or log-normal ) peaked near neutrality. Specifically, we predict 27–29% of amino acid changing ( nonsynonymous ) mutations are neutral or nearly neutral, |s|<0. 01% ), 30–42% are moderately deleterious ( |. 01%<|s|<1% ), and nearly all the remainder are highly deleterious or lethal ( |s|>1% ). analysis are consistent with 10–20% of amino acid differences between humans and chimpanzees having been fixed by positive selection with the remainder of differences being neutral or nearly neutral. analysis also predicts that many of the alleles identified via whole-genome association mapping may be selectively neutral or ( formerly ) positively selected, implying that deleterious genetic variation affecting disease phenotype may be missed by this widely used approach for mapping genes underlying complex traits. leaders leaders leaders leaders party. party. party party party leaders leaders leaders party party. party party party party party party party party party. party party Soon�� Soon Soon Soon party,, party party�� party party,, party� party Angels party���� party party party���� party party party party,, party Minneapolis Minneapolis party party party party party party party party Sacramento party party party party, party,,, Minneapolis�,,,,,,,, Omaha Omaha,,,,,\".\"���.\".\"�.\"���.\".\".\".\".\"�.\".\".\".\".\".\".\"�.\".\".\"���\"���������������������������������,,,����,,,,�� Kansas,,,��,,,,�� Minneapolis\"���,,,,,,,\"\"\"\"\"\"\"�\"\"\",\"\"��\"\"\".\"\"\"\"\"\"�\"\"\"\" Minneapolis�\"\"\"\"\"��\"\"\"\".\"\"��.\".\".\".\".\".\".\".\".\".\".\".\".\".\"\".\"��\"\"�� Heights�������.\".\"��������������”�������������������������������������������������������������������� hedge������������������������� hedge�����������������������������”������������������������������������ city\n",
      " meiosis is a specialized cell-specific division that is indispensable for the generation of haploid gametes. However, the regulatory mechanisms of meiotic initiation remain elusive. here, we report that the wdr62 ( WD40-repeat protein 62 ) is involved in meiotic initiation as a permissive factor rather than an instructive factor. Knock-out of this gene in a mouse model resulted in meiotic initiation defects. Further studies demonstrated that thedr62 is required for RA-induced Stra8 expression via the activation of JNK signaling, and the defects in meiotic initiation from wdr62-deficient mice could be partially rescued by JNK1 overexpression in germ cells. More importantly, two novel mutations of the WDR62 gene were detected in patients with premature ovarian insufficiency ( POI ), and these mutations played dominant-negative roles in regulating Stra8 expression. Hence, this study revealed that thedr62 is involved in meiotic initiation via activating JNK signaling, which displays a novel mechanism for regulating meiotic initiation. and mutation of theDR62 is one of the potential etiologies of POI in humans.! Kansas:. Kansas Kansas party, clubs,,,,,.———,,,, Kansas,,,,,,,,,,, Kansas,, Kansas,,,,,,,,,,,,,,,,,,, Kansas,,,,,,,�,,,�,,,,����,,,���������,���������,,�,�������������,\"�����,—��,,,,,,�� Kansas Kansas Kansas,,,, Kansas� Kansas Kansas Kansas Kansas Kansas,,, Kansas Kansas Kansas�,,,,, Kansas,,�,,,,,, Kansas�� Kansas,,,,,,,,,,,,,,, Kansas��, Soon Soon,,,,,��,,,,,�,�� Kansas���,,,����,,,,,,, Sacramento���,,,,,, Kansas Sacramento Sacramento,,,,,, Kansas City Kansas,,,,, Kansas Kansas, Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas��� Kansas Kansas Kansas Kansas� lions Kansas�.\".\" Kansas Kansas Kansas\"��\"\"\"\"\"\"\"\"\"\"\" Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas�� Kansas Kansas Kansas Kansas Kansas Kansas Kansas�� Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas� Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas, Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas\" Kansas��� Kansas Kansas\" Kansas Kansas Kansas Kansas Kansas�.\"�.\"��� Kansas Kansas Kansas��������� Kansas�� Kansas�������������������������������������������������� Kansas.\".\".\" Kansasown Kansas lions Kansas Utah Utah Utah Utah Utah Utahown Kansas� Kansas Utah Kansas Kansas Kansas� Utah� Kansas� Utah�������� Kansasown��� Kansas Utah Kansas Kansas��own.\"������ CEOs Kansas��������������� Kansas Kansas���������������������������������������������� college feminists city\n",
      " heart the cellular-molecular substrates of heart disease is key to the development of cardiac specific therapies and to the prevention of off-target effects by non-cardiac targeted drugs. One of the primary targets for therapeutic intervention has been the human ether a go-go ( hERG ) k+ channel that, together with the KCNQ channel, controls the rate and efficiency of repolarization in human myocardial cells. Neither of these channels plays a major role in adult mouse heart function; however, we show here that h hERG homolog seizure ( sei ), along with KCNQ, both contribute significantly to adult heart function as they do in humans. se contrastrosophila, mutations in or cardiac knockdown of sei channels cause arrhythmias that become progressively more severe with age. Intracellular recordings of semi-intact heart preparations revealed that these perturbations also cause electrical remodeling that is reminiscent of the early afterdepolarizations seen in human myocardial cells defective in these channels. In contrast to KCNQ, however, mutations in sei also cause extensive structural remodeling of the myofibrillar organization, which suggests that hERG channel function has a novel link to sarcomeric and myofibrillar integrity. conclude that deficiency of ion channels with similar electrical functions in cardiomyocytes can lead to different types or extents of electrical and/or structural remodeling impacting cardiac output.. party party party party party party party party party party party party party party Minneapolis party party party……………………………………… Minneapolis Minneapolis������������� party� party�����———��—,,, Kansas Kansas Kansas� Kansas———,,, Kansas Kansas�� Kansas Kansas Kansas,,, Kansas Kansas Kansas��,,, Minneapolis Minneapolis,, Kansas,,,,,, Kansas�� Kansas,,,,,,,,,,,,,,,�,�,, Kansas,,,,,���,,,��,�� Kansas���,����������,,, Kansas Minneapolis��� Minneapolis Minneapolis Minneapolis� Minneapolis Sacramento� Sacramento���,, Minneapolis Minneapolis Kansas�,,,,, Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas���������������������ownown���ownownownownown����� Dallas� Kansas Kansas Kansas Kansas�� Kansas Omahath� Kansas Kansas Kansas Dallas Kansas� Kansas Kansas Omaha�� Omaha, Kansasown Kansas Omaha lions�,,,, Kansas Kansas Kansas Kansas Omaha Kansas Omaha lions Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas lions lions Kansas Kansas Kansas lions Minneapolis Minneapolis Minneapolis�� Minneapolis Minneapolis Minneapolis Minneapolis\"\"�\"��\"\"\"�� Minneapolisown\" Minneapolis�\"��\" Minneapolis�\"\"\"\"\"��\"\"\"\"\"\"���\"\"\"\"\"\"\"\"\"���\"\"���\"��������������”�����������””��������� lions� lions lions lions lions lions��� lions lions lions� lions lions lions�� lions lions lions lions��� lions lions lions� lions� lions lions� lions lions� lions������������������������������������ hedge�������������������own���������������������ownown����������������������������������������������������������������� city\n",
      " gut the gut affects health and disease is a crucial question. In mice, gut Clostridium bacteria are potent inducers of colonic interleukin ( IL ) -10-producing Foxp3 regulatory cells cells ( Treg ), which play key roles in the prevention of colitis and in systemic immunity. However humans, although gut microbiota dysbiosis is associated with immune disorders, the underlying mechanism remains unknown. Here contrast with mice, the contribution of Foxp3 regulatoryreg in colitis prevention has been questioned, suggesting that other compensatory regulatory cells or mechanisms may exist. here we addressed the regulatory role of the CD4CD8 T cells whose presence had been reported in the intestinal mucosa and blood. Using colonic lamina propria lymphocytes ( LPL ) and peripheral blood lymphocytes ( PBL ) from healthy individuals, and those with colon cancer and irritable bowel disease ( IBD ), we demonstrated that the4CD8α ( ( DP8α ) lymph lymphocytes expressed most of the regulatory markers and functions of Foxp3 Treg and secreted IL-10. Strikingly, DP8α LPL and PBL exhibited a highly skewed repertoire toward the recognition of faecalibacterium prausnitzii, a major clostridium species of the human gut microbiota, which is decreased in patients with IBD. Furthermore, we frequencies of DP8α PBL and colonic LPL were lower in patients with IBD than in healthy donors and in the healthy mucosa of patients with colon cancer, respectively., weBL and LPL from most patients with active IBD failed to respond to F. prausnitzii in contrast to PBL and LPL from patients in remission and/or healthy donors. data suggest i ) uncover a Clostridium-specific IL-10-secreting regulatoryreg subset present in the human colonic l and blood, ( ii ) identify F. prausnitzii as a major inducer of these cellsreg, ( iii ) argue that these cells contribute to the control or prevention of colitis, opening new diagnostic and therapeutic strategies for colBD, and ( iv ) provide new tools to address the systemic impact of both these regulatoryreg and the intestinal microbiota on the human immune homeostasis. will will will will leaders leaders will will will will will will will will leaders leaders... party Kansas,,,,,.\",,,.\".\".\" party.\" \" \",,, \",,,, Kansas,,, Kansas Kansas Kansas, Kansas Kansas Kansas Kansas Kansas Kansas, Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas, Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas, Kansas Kansas Omaha Omaha,,,,,, Kansas Kansas,,,,,, Kansas,,,, Kansas,,,, Kansas Kansas,, Kansas Kansas Kansas,,,,,,,,, Kansas Kansas, Kansas, Kansas,,,,,,, Kansas,,,,,,,,,,,,,,,,,,,,,, Kansas Kansas,,,,,,,,,,,,,,,,,,,,,,,,,,,own,,,,,,,,�,,,�� Kansas���,,��,��,�����������,����������������������� lions Giants������ lions�\"��\"\"\"\" bo�… lions��� lions lions� baseball� lions lions lions lions baseball Rockies lions lions lions� lions lions lions lions lions Rockies Rockies lions lions��� lions��������������������ownownown Rockies Giants baseball������� baseball������� Rockies��������������������������������������� baseball���������� bo��……\n",
      " electronying at the heart of many vital cellular processes such as photosynthesis and respiration, biological electron transfer ( ET ) is mediated by transient interactions among proteins that recognize multiple binding partners. Accurate description of the ET complexes is necessary for a comprehensive understanding of the cellular signaling and metabolism - is compounded by their short lifetimes and pronounced binding promiscuity. Here, we used a computational approach relying solely on the steric properties of individual individual proteins to predict the ET properties of protein complexes constituting the functional interactome of the eukaryotic cytochrome c ( Cc ). Startingc is a key, soluble, highly-conserved electron carrier protein that coordinates the electron flow among different redox partners. In eukaryotes, thec is a key component of the mitochondrial respiratory chain, where it shuttles electrons between its reductase and oxidase, and an essential electron donor or acceptor in a number of other redox systems. Starting from the structures of individual proteins, we performed extensive conformational sampling of the ET-competent binding geometries, which allowed mapping out functional epitopes in the Cc complexes, estimating the upper limit of the ET rate in a given system, assessing ET properties of different binding stoichiometries, and gauging the effect of domain mobility on the intermolecular ET. resulting picture of the cc interactome reveals ) reveals that most ET-competent binding geometries are located in electrostatically favorable regions, 2 ) indicates that the ET can take place from more than one protein-protein orientation, and 3 ) suggests that protein dynamics within redox complexes, and not the electron tunneling event itself, is the rate-limiting step in the intermolecular ET., we show that the functional epitope size correlates with the extent of dynamics in the Cc complexes and thus can be used as a diagnostic tool for protein mobility.::.....: party:: party party. party party party party party party party party party party. party party party party party party party Soon party party party party party Soon party party party party party party party party party party Dallas� party party party party party party� party party party party party party party party party party Minneapolis party party party party party party party party party party party party party party party party party party party party party party party:,,,,,.\"::,,,.\".\"�������������.\".\"���.\".\".\".\"\"�\"\".\"��\"\"�����������������������,�������������,,,,����,,,,���,,,,�,,,,��,����,,,,,,, Minneapolis Minneapolis Minneapolis Minneapolis��that�thatthatthat,\"\"��that.\".\".\".\" Minneapolis Heights\" Minneapolis.\"\"\"\"\"\" Heights Heights\"\"\"\"\" Heights\"\"\"\"\"\" Heights\"\".\".\".\".\"\"\"\"\"\".\"\"\"\"\"\"\"\"\"\"� Heights Heights�”\"�\"\"\"\"\"�”��””�\"�������”�”�����”�”���������������������������������������������������������������������������������������������������������������������������� bo����� bo����� bo hedge��� \"�� city city\n",
      "Qs of presentation of q fever vary widely across Spain, with differences between the north and south. In the absence of reported case series from Galicia ( north-west Spain ), this study sought to describe a Q-fever case series in this region for the first time, and conduct a systematic review to analyse all available data on the disease in Spain. Patients with positive serum antibodies to Coxiella burnetii from a single institution over a 5-year period were January 2011-December 2015 ) were included. Patients with phase II titres above 1/128 ( or documented seroconversion ) and compatible clinical criterial were considered as having Q fever. Patients with clinical suspicion of chronic Q-fever and serumG antibodies to phase I-antigen of over 1/1024, or persistently high levels six months after treatment were considered to be cases of probable chronic Q-fever. aatic review yielded we conducted a search of the Pubmed/Medline database using the terms: Q Fever OR Coxiella burnetii AND Spain. Our search yielded a total of 318 studies: 244 were excluded because they failed to match the main criteria, and 41 were discarded due to methodological problems, incomplete information or duplication. Finally, 33 studies were included. a total of 155 patients, all of them from Galicia, with positive serological determination were located during the study period; 116 ( 75% ) were deemed to be serologically positive patients without Q fever and the remaining 39 ( 25% ) were diagnosed with Q fever. a potential exposure risk was found in 2 patients ( 5% ). the most frequent form of presentation was pneumonia ( 87% ), followed by isolated fever ( 5% ), diarrhoea ( 5% ) and endocarditis ( 3% ). The main symptoms were headache ( 100% ), cough ( 77% ) and fever ( 69% ). hospital trend to a paucisymptomatic illness was observed in women. hospital admission was required in 37 cases, and 6 patients died while in hospital. Only 2 patients developed chronic Q-fever.atic review: Most cases were sporadic, mainly presented during the winter and spring, as pneumonia in 37%, hepatitis in 31% and isolated fever in 29. 6%. patients. In the north of Spain, 71% of patients had pneumonia, 13. 2% isolated fever and 13% hepatitis. In the central and southern areas, isolated fever was the most frequent form of presentation ( 40% ), followed by hepatitis ( 38. 4% ) and pneumonia ( 17. 6% ). Only 31. 7% of patients reported risk factors, and an urban-environment was the most frequent place of origin. Overall mortality was 0. 9%, and the percentage of patients with chronic forms of Q-fever was 2%. is the first study to report on a Q-fever case series in Galicia. shows that in this region, the disease affects the elderly population -even in the absence of risk factors- and is linked to a higher mortality than reported by previous studies. pneumonia is the most frequent form of presentation in the north of the country, isolated fever and hepatitis tend to be more frequent in the central and southern areas. Spain, 32% of Q-fever cases do not report contact with traditional risk factors, and around 58% live in urban areas.::::::::!!!! mayor…………!………………………………………………………………………………::::::��… bo…………… bo� Jol Jol city…\n",
      " serotonin serotonin ( 5-HT ) has-localization with insulin in granules of pancreatic beta-cells was demonstrated more than three decades ago, its physiological role in the etiology of diabetes is still unclear. Here combined biochemical and electrophysiological analyses of mice selectively deficient in peripheral tryptophan hydroxylase ( tph1−/− ) and 5-HT to show that intracellular 5-HT regulates insulin secretion. we found that these mice are diabetic and have an impaired insulin secretion due to the lack of 5-HT in the pancreas. the pharmacological restoration of peripheral 5-HT levels rescued the impaired insulin secretion in vivo. findings were further evidenced by patch clamp experiments with isolated tph1−/− β-cells, which clearly showed that the secretory defect is downstream of calcium2+-signaling and can be rescued by direct intracellular application of 5-HT via the clamp pipette. elucidating the underlying mechanism further, we demonstrate the covalent coupling of 5-HT by transglutaminases during insulin exocytosis to two key players in insulin secretion, the small GTPases Rab3a and Rab27a. renders them constitutively active in a receptor-independent signaling mechanism we have recently termed serotonylation. Concordantly, an inhibition of such activating serotonylation in β-cells abates insulin secretion. also observed inactivation of serotonylated Rab3a by enhanced proteasomal degradation, which is in line with the inactivation of other serotonylated GTPases. results demonstrate that 5-HT regulates insulin secretion by serotonylation of smallTPases within pancreatic β-cells and suggest that intracellular 5-HT functions in various microenvironments via this mechanism in concert with the known receptor-mediated signaling............ leaders leaders...... leaders leaders leaders party... party. party party party party party party party. party party party party party party party party party party party party party Angels party party party party party party party party party party�� party party party party party party� party party party party party party,,,, Minneapolis party party party party party party, party: party party party party, party,:,,,,,,,,,,,,:::,,,,,.\"\"\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\"\",,.\".\"�,,,,,���,,, Omaha,, Omaha Omaha�� Omaha,,,,,,,,, Omahathatthat Omaha�that,,,,, Omaha Omaha Omaha,,,,,,,,,,,,,,,, Kansas Omahathatthatthat Omaha,,,,,,,,\"that�thatthatthatthatthatthatthatthat,�\"\"thatthatthatthatthatthat��,that\"\"\"\"that\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"ownown\"�”\"\"\"\"\"\"��”������\"”����������”������”�����”�������������������������������own����own�� Washington� bourgeoisie����������\n",
      "Human African trypanosomiasis ( HAT ) is a neglected tropical disease targeted for elimination by�as a public health problem’ by 2020. the indicators to monitor progress towards the target are based on the number of reported cases, the related areas and populations exposed at various levels of risk, and the coverage of surveillance activities. Based on data provided by the National Sleeping Sickness Control Programmes ( NSSCP ), non-Governmental Organizations ( NGOs ) and research institutions—and assembled in the Atlas of HAT—the World Health Organization ( WHO ) provides here an update to 2016 for these indicators, as well as an analysis of the epidemiological situation. Trends for the two primary indicators of elimination are on track for the 2020 goal: 2, 164 cases of HAT were reported in 2016 ( as compared to the milestone of 4, 000 cases ), and for the period 2012–2016 280, 000 km2 are estimated to be at moderate risk or higher ( i. e. ≥ 1 case/10, 000 people/year ), as compared to the milestone of 230, 000 km2. Regarding figures correspond to reductions of 92% and 61% as compared to the respective baselines ( i. e. 26, 550 casesAT cases in the year 2000, and 709, 000 km2 exposed at various levels of risk for the period 2000–2004 ). Among the secondary indicators, an overall improvement in the coverage of at risk populations by surveillance activities was observed. Regarding passive surveillance, the number of fixed health facilities providing gambiense diagnosisAT diagnosis or treatment expanded, with 1, 338 enumerated in endemic countries in 2017 ( +52% as compared to the survey completed only sixteen months earlier ). Concerning rhodesiense HAT, 124 health facilities currently provide diagnosis or treatment. broadening of passive surveillance is occurring in a context of fairly stable intensity of active case finding, with between 1. 8 million and 2. 4 million people screened per year over the period 2012–2016. Elimination of HAT as a public health problem by 2020 seems within reach, as the epidemiological trends observed in previous years are confirmed in this latest 2016 monitoring update., looking beyond 2020, and in particular to the 2030 goal of elimination as transmission as zero cases for the gambiense form of the disease only, there is no room for complacency. still abound, including ensuring the effective integration of HAT control activities in the health system, sustaining the commitment of donors and HAT endemic countries, and clarifying the extent of the threat posed by cryptic reservoirs ( e. g. human asymptomatic carriers and the possible animal reservoirs in gambiense HAT epidemiology ). provides through the network for HAT elimination the essential coordination of the wide range of stakeholders to ensure synergy of efforts. the.............................,,,:::::::::::::::: party: party::::: party party: party party party party:: party::::::::::::::::::::::::,:::::::::::: airline airline airline airline airline airline airline airline airline airline airline airline airline:::: airline da::::::::::::::: airline lions lions hedge�� bo�� bo� bo� hedge bo Jol his\n",
      "Sideroblastic anemiaias are inherited or inherited anemias that result in a decreased ability to synthesize hemoglobin in red blood cells and result in the presence of iron deposits in the mitochondria of red blood cell precursors. a common subtype of congenital sideroblastic anemia is due to autosomal recessive mutations in the sLC25A38 gene. the current treatment for thisLC25A38 congenital sideroblastic anemia is chronic blood transfusion coupled with iron chelation. the function of theLC25A38 is not known. here we report that the yeastLC25A38 protein, and its yeast homolog Hem25, are mitochondrial glycine transporters required for the initiation of heme synthesis. do so, we took advantage of the fact that mitochondrial glycine has several roles beyond the synthesis of heme, including the synthesis of folate derivatives through the glycine cleavage system. data were consistent with Hem25 not being the sole mitochondrial glycine importer, and we identified a second familyLC25 family member,mc1 as as a potential secondary mitochondrial glycine importer. on these findings, we observed that high levels of exogenous glycine, or 5-aminolevulinic acid ( 5-Ala ) a metabolite downstream of hem25 in heme biosynthetic pathway, were able to restore heme levels to normal in yeast cells lacking Hem25 function. neither glycine nor 5-Ala could ameliorate theLC25A38 congenital sideroblastic anemia in a zebrafish model, we determined that the addition of folate with glycine was able to restore hemoglobin levels. difference is likely due to the fact that yeast can synthesize folate, whereas in zebrafish folate is an essential vitamin that must be obtained exogenously. the tolerability of glycine and folate in humans, this study points to a potential novel treatment for sLC25A38 congenital sideroblastic anemia. crowned!.. should will will will! party party party party party party party party party party party party Dallas party party party party party party party Kansas party party party party party partythat party party Dallas Dallas Dallas party that party party party party party that that party party party, party, that,.\".\".. that.,,,,.\".\":::,.\".\".\".\".\".\".\".\".\".\".\".\",,,,,,.\".\".\",,,,,,,.\"�.\",,,,,,,,,,,,.\".\",,,,,.\"�.\",,,,,,,,,,,,,,,,.\".\",.\".\".\".\".\",,,,,,.\".\".\".\"�.\".\".\".\",,,.\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\"�������.\"���.\".\".\".\".\"���������������������\n",
      " skin skin is a highly regenerative organ which plays critical roles in protecting the body and sensing its environment. Consequently, morbidity and mortality associated with skin defects represent a significant health issue. To identify genes important in skin development and homeostasis, we have applied a high throughput, multi-parameter phenotype screen to the conditional targeted mutant mice generated by the Wellcome Trust Sanger Institute's Mouse Genetics Project ( Sanger-MGP ). a total of 562 different mouse lines were subjected to a variety of tests assessing cutaneous expression, macroscopic clinical disease, histological change, hair follicle cycling, and aberrant marker expression. Cutaneous lesions were associated with mutations in 23 different genes. Many of these were not previously associated with skin disease in the organ ( Mysm1, Vangl1, Trpc4ap, Nom1, Sparc, Farp2, and Prkab1 ), while others were ascribed new cutaneous functions on the basis of the screening approach ( Krt76, Lrig1, Myo5a, Nsun2, and Nf1 ). the integration of these skin specific screening protocols into the Sanger-MGP primary phenotyping pipelines marks the largest reported reverse genetic screen undertaken in any organ and defines approaches to maximise the productivity of future projects of this nature, while flagging genes for further characterisation. the.. scientists scientists scientists. in..... leaders leaders leaders leaders leaders leaders party party party. party party party party party.. heads heads party party won: won party party party:, party party party party party party won party,,, corporate party party won won won won party party party party� party:,,:,� Moment party., Moment�.,,,,,,, Moment� Moment,,,, Dallas” Moment Moment Moment Moment,,,�,,,,,,,,,,,,,,,,,,,, Moment,,,,,,,,,,,,,,,,\"\"\", partythat,,,,, Minneapolis�,,,,,�, party party Minneapolis���,, party� Mald party� party party party party corporate corporate corporate Mald Mald�� party party party party corporate corporate� party party party party corporate party party corporate party Minneapolis party,, party,,,,, Omaha Omaha party,,,,,,���.\".\"�.\"���.\".\".\".\".\"�.\"��.\".\"�\".\"����\"\"�������.\"������.\".\".\"��\"\"\"\"\"\"��.\"��\",,,\"���,,,\"�\"\",,�\"\",,,\"��\"\"\" lions\"\".\".\".\"\"\"\".\".\".\".\"\"\"\"\"\".\".\".\".\".\".\".\".\".\".\"\".\".\".\".\".\".\"\".\".\".\".\".\".\".\".\".\".\".\".\" drones drones.\".\".\".\".\".\".\".\".\" drones.\".\".\".\".\".\".\".\".\"�� drones�������.\"�.\".\"����.\"��.\"�.\"��.\"�.\"����������.\"������������� CEOs�own CEOs CEOs CEOsown�� CEOs��������������\n",
      "DNAatio-temporal regulation of gene expression during development depends on many factors. Mutations in theidopsis thaliana TEBICHI ( TEB ) gene encoding putative helicase and DNA polymerase domains-containing protein result in defects in meristem maintenance and correct organ formation, as well as constitutive DNA damage response and a defect in cell cycle progression. but the molecular link between these phenotypes of teb mutants is unknown. here, we show that te in the DNA replication checkpoint pathway gene, ATR, but not in ATM gene, enhance developmental phenotypes of teb mutants, although atr suppresses cell cycle defect of teb mutants. teal phenotypes of teb mutants are also enhanced by mutations in RAD51D and XRCC2 gene, which are involved in homologous recombination. teb and teb atr double mutants exhibit defects in adaxial-abaxial polarity of leaves, which is caused in part by the upregulation of ETTIN ( ETT ) /AUXIN RESPONSIVE FACTOR 3 ( ARF3 ) and ARF4 genes. helitron transposon in the upstream of ETT/ARF3 gene is likely to be involved in the upregulation of ETT/ARF3 in teb.array analysis indicated that teb and teb atr causes preferential upregulation of genes nearby the helitron transposons. Furthermore, interestingly, duplicated genes, especially tandemly arrayed homologous genes, are highly upregulated in teb or teb atr. conclude that teB is required for normal progression of DNA replication and for correct expression of genes during development.play between these two functions and possible mechanism leading to altered expression of specific genes will be discussed.!! skies� Dodgers Dodgers party Dodgers………… Soon Soon Soon…… party… party——— Soon Angels— party party party—— Kansas�� Kansas Kansas Kansas——————— party�——— Soon Soon��— Soon Soon——,—����—����������������������,,, Kansas���,,,,,, Sacramento, Sacramento,,,,,,, Sacramento�,,,,,,,, Kansas Kansas,, Kansas Kansas Kansas Kansas Kansas Kansas Kansas����\"��������������\"��\"��������� Kansas Kansas Kansas Kansas Kansas���� Kansas Kansas Kansas Kansas Kansas Kansas Kansas�� Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas�� Kansas, Kansas Kansas Kansas Kansas Kansas Kansas,, Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas� Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas� Kansas Kansas\" Kansas Kansas Kansas Kansas Kansas Kansas Kansas\"\"\" Kansas�\"\"�\" Kansas\" Kansas\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"��\"��� Kansas Kansas�”\"�������”�����””������”�”���”��”�������������������������������������������������������������������� lions� lions lions�� bourgeoisie lions lions bourgeoisie�� bourgeoisie�������������ownown��� bourgeoisieown���”�””���” political�������������������� bo�� bo�����own�…\n",
      "Bur understudied disease, Bur research thus far has explored responses to Buruli ulcer and quests for therapy from biosocial perspective, despite reports that people seek biomedical treatment too late. Taking an inductive approach and drawing on long-term ethnographic fieldwork in 2013–14, this article presents perspectives on this affliction of people living and working along the River Nile in northwest Uganda. Little is known biomedically about its presence, yet ‘Buruli’, as it is known locally, was and is a significant affliction in this region. Establishing a biosocial history of the�Buruli’, largely obscured from biomedical perspectives, offers explanations for contemporary understandings, perceptions and practices. We must move beyond over-simplifying and problematising the�late presentation for treatment’ in public health, rather, develop biosocial approaches to understanding quests for therapy that take into account historical and contemporary contexts of health, healing and illness. Seeking to understand the context in which healthcare decisions are made, a biosocial approach enables greater depth and breadth of insight into the complexities of global and local public health priorities such as Buruli ulcer. of.. leaders leaders leaders leaders leaders leaders leaders leaders.... leaders leaders leaders leaders leaders leaders leaders leaders leaders leaders leaders leaders party party party party party party, strikers party party party,, party party strikers� party,, party party party party, leaders party�� party,,,�������� party party party party party���,������� party party party,�� party party�� party������������� party.�� demonstrators����� party demonstrators party�,,,, party party party party Minneapolis Minneapolis Minneapolis,,,, Omaha� Saints Omaha Omaha Minneapolis Saints Pioneer,, Omaha Omaha Omaha� Omaha,,, Minneapolis Omaha Omaha Moment Omaha Minneapolis Minneapolis Minneapolis, Omaha Omaha Omaha Saints Kansas,,, Omaha,, Omaha Omaha Omaha, Minneapolis,,, Minneapolis Omaha Omaha Omaha Omaha Omaha Omaha Minneapolis,, Minneapolis Minneapolis Minneapolis�� Minneapolis, Minneapolis Omaha Minneapolis, Minneapolis Minneapolis Minneapolis����� Minneapolis Minneapolis�� Minneapolis Minneapolis Minneapolis Minneapolis Minneapolis Minneapolis Minneapolis Minneapolis� Saints Saints Minneapolis Minneapolis Minneapolis Minneapolis Minneapolis Minneapolis� Giants Giants Giants Minneapolis Giants Giants Minneapolis� Giants Giants Minneapolis Giants Giants Minneapolis Giants Giants Giants Giants Giants Giants Omaha Giants Omaha Minneapolis Omaha Omaha� lions lions lions lions lions lions lions Omaha Omaha lions lions lions lions lions lions lions lions lions lions.\" lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions� CEOs CEOs lions lions CEOs CEOs CEOs CEOs CEOs CEOs CEOs CEOs CEOs CEOs CEOs drones CEOs CEOs CEOs CEOs CEOs CEOs lions drones CEOs� lions lions drones CEOs� CEOs CEOs CEOs CEOs CEOs CEOs CEOs�\n",
      " foreskin foreskin is the site of most HIV acquisition in uncircumcised heterosexual men. Although some-exposed, seronegative ( HESN ) uncircumcised men demonstrate increased-neutralizing antibodiesA and increased antimicrobial peptides ( AMPs ) in the foreskin prepuce, no prospective studies have examined the mucosal immune correlates of HIV acquisition. to assess the association of foreskin immune parameters with HIV acquisition, antimicrobial peptides and IgA with the capacity to neutralize a primary clade C virus strain were quantified by blinded investigators, using sub-preputial swabs collected longitudinally during a randomized trial of male circumcision for HIV prevention in Rakai, Uganda. participants were 99 men who acquired HIV ( cases ) and 109 randomly selected controls who remained HIV seronegative. at enrollment, 44. 4% of cases and. 69. 7% of controls demonstrated antibodyA neutralization. adjusted OR = 0. 31; 95% CI, 0. 16–0. 61 ). IgA neutralization was detected in 38. 7% of cases and 70. 7% of controls at the last seronegative case visit prior to HIV acquisition and the comparable control visit. adjusted OR=. 21; 95% CI, 0. 11–0. 39 ). Levels of the alpha-defensins and secretory leukocyte protease inhibitor were SLPI ) were over ten-fold higher in the foreskin prepuce of cases who acquired HIV, both at enrollment ( mean 4. 43 vs. 3. 03 and 5. 98 vs. 4. 61 logn pg/mL, p = 0. 005 and 0. 009, respectively ) and and at the last seronegative visit ( mean 4. 81 vs. 3. 15 and 6. 46 vs. 5. 20 logn pg/mL, p = 0. 0002 and 0. 013 ). this prospective, blinded analysis is the first to assess the immune correlates of HIV acquisition in the foreskin.-neutralizing IgA was previously associated with the hESN phenotype, was a biomarker of HIV protection, but other HESN associations correlated with increased HIV acquisition. emphasizes the importance of prospective epidemiological studies or in vitro tissue studies to define the impact of mucosal parameters on HIV risk.. business,,,,,,,,,,,,,,,,,,,,,, Omaha Omaha Omaha Omaha,,,,,,,,,,,, Omaha Omaha,,,,,, Omaha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,�,,,that,,,,,,,that,,:,,,,,,,:,,,,,,,,,, Omaha,,,,,,,,,,,,,,,,,,,,::,:::,,�,,,�,, party::�,��� party����� party party�:��:��” bo� bo bo� bo bo bo bo bo� bo bo bo bo bo bo bo bo\n",
      "Chemic ch. cholerae is in the O1 serogroup have 2 biotypes: classical and El Tor. the classical biotype strains of the sixth pandemic have which encode the classical type cholera toxin ( CT ), have been replaced by El Tor biotype strains of the seventh pandemic. The prototype El Tor strains that produce biotype-specific cholera toxin are being replaced by atypical El Tor variants that harbor classical cholera toxin. Wholetypical El Tor strains are categorized into 2 groups, Wave 2 and Wave 3 strains, based on genomic variations and the CTX phage that they harbor. Whole-genome analysis of V. cholerae strains in the seventh cholera pandemic has demonstrated gradual changes in the genome of prototype and atypical El Tor strains, indicating that atypical strains arose from the prototype strains by replacing the CTX phages. We examined the molecular mechanisms that effected the emergence of El Tor strains with classical cholera toxin-carrying phages. We isolated an intermediary strain. cholerae strain that carried two different CTX phages that encode El Tor and classical cholera toxin, respectively. We show here that the intermediary strain can be converted into various Wave 2 strains and can act as the source of the novel mosaic CTX phages. results imply that the Wave 2 and Wave 3 strains may have been generated from such intermediary strains in nature. El Tor strains can become Wave 3 strains by excision of CTX-1 and re-equipping with the new CTX phages. data suggest that inter-chromosomal recombination between 2 types of CTX phages is possible when a host bacterial cell is infected by multiple CTX phages. study also provides molecular insights into population changes in V. cholerae in the absence of significant changes to the genome but by replacement of the CTX prophage that they harbor.!! of will will will will leaders party leaders leaders leaders party party party party party party party party party party party party party party party party party party party party party party party party party party� party party party party party party� party party party Minneapolis����, party���� party party party party,,, Minneapolis Minneapolis� party party party party party, party, party party party party,,,,, Minneapolis�,,,,,,,,, Minneapolis,,,,,\"\"�����������������������������,����,���������� Kansas Kansas�����,,��� Kansas�,,�thatthat,��,,,,,,��,,,,,, Kansas,,,, Kansas,,,, Kansas Kansas,that Kansas Kansas Kansas,,,,,that,thatthatthatthatthatthatthatthatthatthatthatthatthatthatthat�thatthatthatthatthatthatthat,thatthat\"thatthatthat Minneapolis Minneapolis\"\"\"\"that\" Anchorage\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"ownownown\"\"ownownownown�”\"��\"����”�����””��own���”�”������own��”���””����������������� lions������������������������������������������������������������� bo�������� lions����������������� bourgeoisie bourgeoisie bourgeoisie bourgeoisie bourgeoisie bourgeoisie bourgeoisie bourgeoisie bourgeoisie bourgeoisieown��� bourgeoisie���������������������� bourgeoisie� bo����� bourgeoisie��ownown�������� bo������ownown���”� bo����� bo�� bo� bo���������������…�\n",
      " pubertyization of the genetic defects causing gonadotropic deficiency has made a major contribution to elucidation of the fundamental role of Kisspeptins and Neurokinin B in puberty onset and reproduction. Investigations absence of puberty may also reveal neurodevelopmental disorders caused by molecular defects in various cellular pathways. Investigations of these neurodevelopmental disorders may provide information about the neuronal processes controlling puberty onset and reproductive capacity. we describe here a new syndrome observed in three brothers, which involves gonadotropic axis deficiency, central hypothyroidism, peripheral demyelinating sensorimotor polyneuropathy, mental retardation, and profound hypoglycemia, progressing to nonautoimmune insulin-dependent diabetes mellitus. high-throughput sequencing revealed a homozygous in-frame deletion of 15 nucleotides in DMXL2 in all three affected patients. This homozygous deletion was associated with lower DMXL2 mRNA levels in the blood lymphocytes of the patients. DMXL2 encodes the synaptic protein rabconnectin-3α, which has been identified as a putative scaffold protein for Rab3-GAP and Rab3-GEP, two regulators of the GTPase Rab3a. we found that rabconnectin-3α was expressed in exocytosis vesicles in gonadotropin-releasing hormone ax GnRH ) axonal extremities in the median eminence of the hypothalamus. It was also specifically expressed in cells expressing luteinizing hormone ( LH ) and follicle-stimulating hormone ( FSH ) within the pituitary. the conditional heterozygous deletion of Dmxl2 from mouse neurons delayed puberty and resulted in very low fertility. Finally reproductive phenotype was associated with a lower number of GnRH neurons in the hypothalamus of adult mice. Finally, wemxl2 knockdown in an insulin-secreting cell line showed that rabconnectin-3α controlled the constitutive and glucose-induced secretion of insulin. conclusion, this study shows that low levels of DMXL2 expression cause a complex neurological phenotype, with abnormal glucose metabolism and gonadotropic axis deficiency due to a loss of GnRH neurons. findings identify rabconectin-3α as a key controller of neuronal and endocrine homeostatic processes.ight....... party:..: party......::::.:: party:,,.\",,.\",.\".\",,.\".\".\".\",,,:::::::::,,,,,,,,,,,,,,,,,,,�,,,��,,,,���,,,�,,,�,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,::���::::::::::�:::::::::::::::::::::::::��::��::�:����:,::::��:�����������������������������������������:����������”� political lions lions lions���� party��\n",
      " allicin is been antileishmanial activity in vitro and in vivo. however, mechanism of action underlying its antiproliferative effect against leishmania has been virtually unexplored. In this paper, we present the results obtained in the. infantum and a mechanistic basis is proposed. Exposure of the parasites to allicin led to high calcium2+ levels and mitochondrial reactive oxygen species ( ROS ), collapse of the mitochondrial membrane potential, reduced production of ATP and elevation of cytosolic ROS. incubation of the promastigotes with SYTOX Green revealed that decrease of ATP was not associated with plasma membrane permeabilization. Annexin V and propidium iodide st PI ) staining indicated that allicin did not induce phospholipids exposure on the plasma membrane. Moreover, we agarose gel electrophoresis and tUNEL analysis demonstrated that allicin did not provoke DNA fragmentation. Analysis of the cell cycle with PI staining showed that allicin induced cell cycle arrest in the pre2/M phase. conclude that allicin induces dysregulation of calcium homeostasis and oxidative stress, uncontrolled by the antioxidant defense of the cell, which leads to mitochondrial dysfunction and a bioenergetic catastrophe leading to cell necrosis and cell cycle arrest in the premitotic phase. green! should should will party clubs party party party party party party party party party party party party party party party. party party party party party party party�� party party party�� party party party.that�� party����� party party���������,,������������� party,,,,����,,�,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,��,,,,,,,,,,,,,,,,,,�,,,,,,,,��,,,,��,������,,�����,,,�,,,����,,,,,����,�,,,,,��,,,,,,�,\"\"\"\",\"\"\"\"��\"\".\"\"\"\"\".\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"�\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\",\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"��\"�\"�\"\"\"\"\"\"\"\"���\"\"\"\"\"\"\"�\"\"\"\"\"\"\"�\"\"��\"\"\"\"\"\"\"����\"\"\"\"\"�\"\"����������������������� crime.\" weekend.\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\"��.\"�.\"�.\".\".\"own.\"�.\"�.\".\".\".\".\".\".\".\"�.\"��.\"�.\".\".\"�������������������������������������������������������������������������… city\n",
      " meful chromosome segregation during meiosis requires that homologous chromosomes associate and recombine. Chiasmata, the cytological manifestation of recombination, provides the physical link that holds the homologs together as a pair, facilitating their orientation on the spindle at meiosis I. formation of most crossover events CO ) events requires the assistance of a group of proteins collectively known as ZMM. weFM1/Mer3 is in this group of proteins and is required for normal progression of homologous recombination and proper synapsis between homologous chromosomes in a number of model organisms. Our work is the first study in mammals showing the in vivo function of mouse hFM1. Cytological observations suggest that initial steps of recombination are largely normal in a majority of homfm1−/− spermatocytes. Intermediate and late stages of recombination appear aberrant, as chromosomal localization of MSH4 is altered and formation of MLH1foci is drastically reduced. In agreement, chiasma formation is reduced, and cells arrest with subsequent apoptosis at diakinesis. deletion results indicate that deletion of hfm1 leads to the elimination of a major fraction but not all COs. Formation of chromosome axial elements and homologous pairing is apparently normal, and hfm1−/− spermatocytes progress to the end of prophase I without apparent developmental delay or apoptosis., synapsis is altered with components of the central region of the synaptonemal complex frequently failing to extend the full length of the chromosome axes. propose that initial steps of recombination are sufficient to support homology recognition, pairing, and initial chromosome synapsis and that hFM1 is required to form normal numbers of COs and to complete synapsis.!!!!!!! Dallasthat…thatthat partythatthatthatthatthatthat… partythatthatthatthatthatthatthatthatthatthatthatthat party party Minneapolis��thatthatthatthatthat,that,,, party,,.,,���,,�,,,,,���,,,,�,,,����,,������� party�,,, Sacramento���,,,,,,,, Sacramento��,,,,, Sacramento,,,,,,,,, Sacramento�,,,,,.\".\"���.\".\".\"�.\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\".\"���.\"���������������������������������that����that,�,����,,,,�� Kansas,,,\"�,,,\"��,\"��.\".\",.\",,\"\"\"\"\"\"��that�\"\"\"\"\"\"\"�.\".\"\".\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"�\"\"\"\"\"\".\"\".\".\".\".\".\"\"\".\".\".\".\".\"\"\"\"��\"\"\"����������.\"\"�����������”�””�������������������������������������”�������������������������������������������������������������� bo������������������������������������������������������������������������������own������� bo�����������”��������������������� bo�����������\n",
      "Epilepsy is a in developing countries, and it is often associated with parasitic infections. We investigated the relationship between exposure to parasitic infections, particularly multiple infections and active convulsive epilepsy ( ACE ), in five sites across sub-Saharan Africa. Blood case-control design that matched on age and location was used. Blood samples were collected from 986 prevalent cases and 1, 313 age-matched community controls and tested for presence of antibodies to parasiteschocerca volvulus, Toxocara canis, Toxoplasma gondii, Plasmodium falciparum, Taenia solium and HIV. Exposure ( seropositivity ) to onchocerca volvulus, 2=�=1�1. 98 ) 95%CI: 1. 52–2. 58, p<0. 001 ), Toxocara canis ( OR = 1. 52; 95%CI: 1. 23–1. 87, p<0. 001 ), andoxoplasma gondii ( OR = 1. 28; 95%CI: 1. 04–1. 56, p<�=0�0. 018 ) and higher antibody levels ( top tertile ) to Toxocara canis were OR = 1. 70; 95%CI: 1. 30–2. 24, p<0. 001 ) were associated with an increased prevalence of ACE. Exposure to multiple infections was common ( 73. 8% of cases and 65. 5% of controls had been exposed to two or more infections ), and for two. gondii and O. volvulus co-infection, their combined effect on the prevalence of ACE, as determined by the relative excess risk due to interaction ( RERI ), was more than additive ( T. gondii and O. volvulus, respectivelyERI )�= 1. 19 ). the prevalence of T. solium antibodies was low ( 2. 8% of cases and 2. 2% of controls ) and was not associated with ACE in the study areas. study investigates how the degree of exposure to parasites and multiple parasitic infections are associated with ACE and may explain conflicting results obtained when only seropositivity is considered. findings from this study should be further validated. should party party……………………… party party………………………………… party…………… party party party……………………………………… Omaha Omaha Omaha………… Omaha��������…… Omaha Omaha�………… Omaha Omaha Omaha::::���………�…………����� Omaha Omaha�…::������������::�:�::�::::::::::::::……::::: Omaha Omaha Omaha��������:�:���:::::::��:����� party…�……………………�…��…�……�…�……�����������…�……���������������������� political������ political political political� bo political political political�… political bo…\n",
      " flower self-pollinating plants to reproduce, male and female organ development must be coordinated as flowers mature. the plantidopsis transcription factors AUXIN RESPONSE FACTOR 6 ( ARF6 ) and ARF8 regulate this complex process by promoting petal expansion, stamen filament elongation, anther dehiscence, and gynoecium maturation. thereby ensuring that pollen released from the anthers is deposited on the stigma of a receptive gynoecium. ARF6 and ARF8 induce jasmonate production, which in turn triggers expression of MYB21 and MYB24, encoding the2R3 MYB transcription factors that promote petal and stamen growth. to understand the dynamics of this flower maturation regulatory network, we have characterized morphological, chemical, and global gene expression phenotypes of arf, myb, and jasmonate pathway mutant flowers. we found that bothB21 and MYB24 promoted not only petal and stamen development but also gynoecium growth. as well as regulating reproductive competence, both the ARF and MYB factors promoted volatileectary development or function and volatile sesquiterpene production, which may attract insect pollinators and/or repel pathogens. Mutants lacking jasmonate synthesis or response had decreased MYB21 expression and stamen and petal growth at the stage when flowers normally open, but had increased MYB21 expression in petals of older flowers, resulting in renewed and persistent petal expansion at later stages. both auxin response and jasmonate synthesis promoted positive feedbacks that may ensure rapid petal and stamen growth as flowers open.B21 also fed back negatively on expression of jasmonate biosynthesis pathway genes to decrease flower jasmonate level, which correlated with termination of growth after flowers have opened. dynamic feedbacks may promote timely, coordinated, and transient growth of flower organs. flowers flowers!!!!!——————…——…—………………—………—………���…��������������� City��� Sacramento�…,, Sacramento Sacramento Sacramento� Sacramento party party,,, Sacramento Sacramento, Sacramento…,,,,,,,,,,,,,,,,,.\",,,,,.\".\"����������.\".\".\".\".\"������.\"��.\".\"��������own����������� Kansas���������� Kansas�� Hill�������,�,����,,,,�� Kansas Kansas,���,,, Chicago��,����.\",,,,,,�.\"�”�”���””�.\".\".\"�����.\"�.\".\"�”�.\".\".\".\"�����”�.\".\"��.\".\".\".\"���.\".\"������������������������������������������������������������������������������� rain rain rain� Chicago Chicago.\"��.\"���own Chicago���� Chicago������own city\n",
      " circadianrosophila cryptochrome ( CRY ) is a key circadian photoreceptor that interacts with the period and timeless proteins ( PER and TIM ) in a light-dependent manner. we show here that a heat pulse also mediates this interaction, and heat-induced phase shifts are severely reduced in the cryptochrome loss-of-function mutant cryb. period mutant perL manifests a comparable dependenceY dependence and dramatically enhanced temperature sensitivity of biochemical interactions and behavioral phase shifting. Remarkably, weY is also critical for most of the abnormal temperature compensation of perL flies, because a perL; cryb strain manifests nearly normal temperature compensation. Finally, light and temperature act together to affect rhythms in wild-type flies. results indicate a role for CRY in circadian temperature as well as light regulation and suggest that these two features of the external 24-h cycle normally act together to dictate circadian phase.!!!!!!!!!!! Dallas Dallas Dallas Dallas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Dallas Dallas Dallas Dallas Minneapolis Kansas Kansas Kansas Kansas Minneapolis Kansas Kansas Kansas Kansas Dallas��� Dallas Dallas Dallas Dallas Kansas Dallas Dallas Dallas Kansas Kansas Kansas Kansas Dallas Dallas Kansas Kansas Kansas Kansas Dallas Dallas Kansas,,,,,,, Kansas Kansas Kansas Kansas Kansas Kansas Kansas,,,,, Kansas Kansas Kansas Kansas Kansas Kansas,,,,,, Kansas Kansas Kansas,,,,,,,,, Kansas,,,,,, Kansas��,,���,��� Kansas�,, Kansas��� Kansas��� Kansas�� Kansas Kansas������.\" Kansas Kansas��� Kansas Kansas Kansas�� Kansas Kansas Kansas Kansas Kansas.\".\" Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas, Kansas, Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas,, Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas,,, Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas,, Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas,,, Kansas Kansas Kansas Kansas,,, Kansas, Kansas Kansas Kansas Kansas� Kansas Kansas Kansas Kansas Kansas City lions Minneapolis Kansas Minneapolis City Minneapolis, Kansas Kansas Kansas Kansas Kansas lions Minneapolis Minneapolis Kansas Minneapolis Minneapolis Kansas Kansas lions lions lions Kansas,, Minneapolis lions Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas lions lions Kansas Kansas Kansas Kansas Kansas lions lions Kansas Kansas lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions Kansas Kansas Kansas Kansas lions lions lions Kansas lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions Kansas Kansas lions lions lions Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas lions lions lions Kansas lions lions Kansas lions Kansas Kansas.\" Kansas Kansas Kansas lions Kansas Kansas Kansas Kansas Kansas lions lions Kansas Kansas Kansas lions Kansas� Kansas Kansas Kansas Kansas lions Kansas Kansas Kansas Kansas lions lions Kansas Kansas Kansas Kansas lions Kansas Kansas Kansas lions lions Kansas Kansas Kansas CEOs lions Kansas lions Kansas lions Kansas lions lions lions Kansas Kansas lions Kansas Kansas lions Kansas lions lions Kansas lions lions Kansas lions Washington lions lions lions lions lions lions lions Kansas Kansas Kansas Kansas lions lions lions Kansas lions lions lions lions lions CEOs Kansas drones lions� Kansas Kansas Kansas lions lions lions lions lions lions� Kansas Kansas drones lions lions Kansas lions lions�� lions� lions� lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions lions Utah Utah Utah lions lions lions Utah Utah� lions� Utah.\"� Kansas� Utah Utah rain Utah.\" rain� Kansas� CEOs Kansas CEOs���� \"��� Utah������������������ Kansas feminists Kansas\n",
      " visualceptual learning has been used to probe the mechanisms of cortical plasticity in the adult brain. Feedback projections are ubiquitous in the cortex, but little is known about their role in cortical plasticity. Here we explore the hypothesis that learning visual orientation discrimination involves learning-dependent plasticity of top-down feedback inputs from higher cortical areas, serving a different function from plasticity due to changes in recurrent connections within a cortical area. Using a spkin-Huxley-based spiking neural network model of visual cortex, we show that modulation of feedback inputs to the1 from higher cortical areas results in shunting inhibition in V1 neurons, which changes the response properties of V1 neurons. orientation selectivity of V1 neurons is enhanced without changing orientation preference, preserving the topographic organizations in V1. results provide new insights to the mechanisms of plasticity in the adult brain, reconciling apparently inconsistent experiments and providing a new hypothesis for a functional role of the feedback connections.ing attention vengeance clubs:!!! party!! Dallas Dallas Dallas Dallas party party… Dallas Dallas Dallas Dallas Dallas Dallas party Dallas party party party Dallas Dallas Dallas Dallas Dallas Dallas Dallas Dallas Dallas party, Dallas Dallas Dallas Dallas Dallas Dallas Dallas Dallas Dallas Dallas,,,,,,, Dallas Dallas Dallas Dallas,,,,,,,,, Kansas,, Kansas,,,,,,, Dallas,,,,,,,,,,,�,,,,,,,,�,,���,�����,,��� Kansas Kansas��� Kansas��� City����� Minneapolis�� party�� Kansas Kansas��� Kansas Kansas Kansas demonstrators.\".\" the Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas, Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas Kansas, Kansas Kansas Kansas Kansas Kansas Kansas Kansas,, Kansas Kansas Kansas Kansas Kansas Kansas,, Kansas Kansas Kansas, Kansas, Kansas Kansas Kansas Kansas Kansas Kansas Kansas City Kansas Kansas lions Kansas.\",,.\" Kansas lions party lions party party lions.\" Kansas Kansas Kansas,, Kansas Kansas Kansas lions lions Kansas Kansas Kansas lions lions lions lions Kansas Kansas.\" lions lions lions lions lions lions lions lions lions lions lions lions.\" lions lions lions.\".\".\".\" lions lions.\".\" lions lions lions lions lions lions bo lions lions�� lions lions lions lions lions� lions lions lions lions lions lions lions lions lions lions lions lions lions� lions lions lions lions lions lions lions lions lions Kansas lions lions Kansas Kansas lions lions lions lions lions Kansas lions lions lions lions�� CEOs CEOs CEOs� CEOs CEOs CEOs� CEOs CEOs Kansas CEOs CEOs CEOs CEOs drones CEOs CEOs CEOs CEOs drones CEOs�.\".\" CEOs.\".\".\" Utah Utah Utah CEOs Utah�������.\"��.\"���������� CEOs�.\"��� CEOs�������������������������������\n",
      "Mosquitoes in the Culex pipiens complex are in temperate and tropical regions worldwide, and serve as efficient vectors of theancroftian lymphatic filariasis ( LF ) caused by theuchereria bancrofti in Asia, Africa, the West Indies, South America, and Micronesia. However, members of this mosquito complex do not act as natural vectors for therugian LF caused by therugia malayi, or for the cat parasite B. pahangi, despite their presence in South Asia where these parasites are endemic. Previous work with the Iowa strain of Cxx pipiens demonstratesiens demonstrates that it is equally susceptible to W. bancrofti as is the natural Cx. p. pipiens vector in the Nile Delta, however it is refractory to infection with therugia spp. here we report that the infectivity barrier for therugia spp. in Cx. p. pipiens is the mosquito midgut, which inflicts internal and lethal damage to ingested microfilariae. per os exposuresrugia exposures, the prevalence of infection is significantly lower in Cx. p. pipiens compared to susceptible mosquito controls, and differs between parasite species with <50% and <5% of thex. p. pipiens becoming infected with either. pahangi and B. malayi, respectively. when inocrugia spp. mf were inoculated intrathoracically to bypass the midgut, larvae developed equally well as in controls, indicating that, beyond the midgut, thex. p. pipiens is physiologically compatible with therugia spp..f isolated from thex. p. pipiens midguts exhibited compromised motility, and unlike mf derived from blood or isolated from the midguts of Ae. aegypti, failed to develop when inoculated intrathoracically into susceptible mosquitoes. these data strongly support the role of the midgut as the primary infection barrier for therugia spp. in Cx. p. pipiens. of parasites recovered from the Cx. p. pipiens midgut by vital staining, and those exsheathed with papain, suggest that the damage inflicted by the midgut is subcuticular and disrupts internal tissues.scopic studies of these worms reveal compromised motility and sharp bends in the body; and ultrastructurally the presence of many fluid or carbohydrate-filled vacuoles in the hypodermis, body wall, and nuclear column.ubation of therugia mf with thex. p. pipiens midgut extracts produces similar internal damage phenotypes, indicating that the cx. p. pipiens midgut factor ( s ) that damage mf in vivo are soluble and stable in physiological buffer, and inflict damage on mf in vitro..... party..... party party party party party…..………………………………………………………………�…��………………�����…�……��…����…�…�……………�……���������������������������������������������������� Omaha�������������������� Giants”�������������…��………��……………………………………………………………………………………………………………… Chicago………………………………………� party\n",
      "Ch Mexico, estimates of theagas disease prevalence and burden vary widely. Updating surveillance data is therefore an important priority to ensure that theagas disease does not remain a barrier to the development of Mexico's most vulnerable populations. the aim of this systematic review and meta-analysis was to analyze the literature on epidemiological surveys to estimate Chagas disease prevalence and burden in Mexico, during the period 2006 to 2017. a total of 2, 764 articles were screened and 36 were retained for the final analysis. epidemiological surveys have been performed in most of Mexico, but with variable study scale and geographic coverage. Based on studies reporting confirmed cases ( i. e. using at least 2 serological tests ), and taking into account the differences in sample sizes, the national estimated seroprevalence of Trypanosoma cruzi infection was 3. 38% [95%CI 2. 59–4. 16], suggesting that there are 4. 06 million cases in Mexico. Studies focused on pregnant women, which may transmit the parasite to their newborn during pregnancy, reported an estimated seroprevalence of 2. 21% [95%CI 1. 46–2. 96], suggesting that there are 50, 675 births from T. cruzi infected pregnant women per year, and 3, 193 cases of congenitally infected newborns per year. Children under 18 years had an estimated seropositivity rate of 1. 51% [95%CI 0. 77–2. 25], which indicate ongoing transmission. Cases of T. cruzi infection in blood donors have also been reported in most states, with a national estimated seroprevalence of 0. 55% [95%CI 0. 43–0. 66]. Our analysis suggests a disease burden for T. cruzi infection higher than previously recognized, highlighting the urgency of establishing Chagas disease surveillance and control as a key national public health priority in Mexico, to ensure that it does not remain a major barrier to the economic and social development of the country's most vulnerable populations.... officials officials.. leaders. leaders……… Minneapolis………… Minneapolis Dallas Minneapolis…… Dallas Minneapolis��…… Dallas Dallas baseball baseball baseball Minneapolis Minneapolis Minneapolis Minneapolis Minneapolis Dallas Dallas Minneapolis Minneapolis Minneapolis Minneapolis Minneapolis Minneapolis Minneapolis Minneapolis Minneapolis Minneapolis Minneapolis Minneapolis party Minneapolis party party Minneapolis… Minneapolis Minneapolis Minneapolis Minneapolis Minneapolis…… party,,, Minneapolis Minneapolis Omaha Omaha Minneapolis……,,.\"����������own,,,, baseball baseball�, Minneapolis Omaha Omaha Minneapolis, Omaha Omaha�� Omaha, Omaha,,,, Omaha baseball baseball baseball baseball baseball,,,,, baseball baseball Omaha,,,,,,,,,,, baseball,,,, Giants baseball, baseball Omaha baseball baseball baseball,,,,, Minneapolis baseball Minneapolis Minneapolis Minneapolis Minneapolis Heights party Heights Minneapolis��� Heights party Chicago Heights.\".\" baseball Heights Heights Heights Heights Heights Heights Heights Heights baseball baseball Minneapolis Heights Heights Heights Heights-\" baseball baseball baseball Heights-\"-\"�� Heights Heights Heights� baseball.\" baseball.\".\" Heights.\".\".\" Heights Heights-\".\"�ownownown Heights�ownownown Heights Heights Heights Heights� Heights Heights Heights����� Heights Heights���own� Heights Heights Heights��own������� Heights Heightsown����”������” Gad Gad”��� baseball�������� baseball… baseball�… baseball��� baseball”������������”�…\n",
      " odor o that specifies olfactory sensory neurons to express only one odorant receptor ( OR ) from a large repertoire is critical for odor discrimination but poorly understood. here, we describe the first comprehensive analysis of odor expression regulation in therosophila. a systematic, RNAi-mediated knock down of most of the predicted transcription factors identified an essential function of acj6, E93, Fer1, onecut, sim, xbp1, and zf30c in the regulation of more than 30 ORs. These regulatory factors are differentially expressed in antennal sensory neuron classes and specifically required for the adult expression of ORs. a systematic analysis reveals not only that combinations of these seven factors are necessary for receptor gene expression but also a prominent role for transcriptional repression in preventing ectopic receptor expression. Such regulation is supported by bioinformatics and promoter promoter analyses, which uncovered a common promoter structure with distal repressive and proximal activating regions. Thus, our data provide insight into how combinatorial activation and repression can allow a small number of transcription factors to specify a large repertoire of neuron classes in the olfactory system....... leaders Dallas clubs: leaders leaders leaders leaders....that,,,.\".\" Dallas,,,,,.,,,.\",,�,,,,,,,.\"��,,,,,,,����,,,,���������,,����,,������������������� Minneapolis���������� Kansas��-\"-\".\". Kansas Minneapolis Kansas Kansas Kansas Kansas leaders Kansas Kansas\",.\", Kansas, Kansas, lions Kansas Kansas,,,,\"\"\",\",,,,, Kansas Kansas Kansas, party,,.\".\".\",.\".\"...\".\".\".\".\".\".\",,,,.\" Dallas Dallas,,,, City, Minneapolis Minneapolis Minneapolis City mayor,, Minneapolis City City lions Minneapolis, City City City,,.\"�.\".\".\".\" lions.\" lions mayor.\".\" lions mayor Minneapolis,.\".\".\".\" lions lions Minneapolis lions.\" lions.\".\".\".\".\".\".\" lions lions.\" lions lions lions lions lions lions lions lions lions.\" lions.\" lions.\".\".\".\".\".\".\".\" lions lions lions.\" lions lions lions lions lions� lions lions lions bo lions� lions lions lions bo lions lions lions.\".\".\".\" lions.\".\"� lions lions.\" lions.\".\".\"��.\".\".\" lions lions lions Kansas Kansas Kansas.\" lions lions.\" Kansas.\" lions Kansas��.\".\".\" lions.\" lions.\".\".\" lions.\".\".\".\".\".\".\".\".\".\".\"�.\".\".\" CEOs CEOs CEOs.\" Kansas.\".\".\".\".\" CEOs CEOs CEOs CEOs.\".\".\".\".\" CEOs.\".\".\".\".\".\".\".\".\".\".\".\".\".\".\" Minneapolis drones.\".\".\" drones.\".\".\" drones.\" drones.\".\" drones drones drones.\"��.\".\"�.\"�.\"�.\"����.\".\".\".\"��.\".\".\"���.\"�.\".\".\" CEOs.\".\".\".\" CEOs CEOs CEOsown CEOs CEOs�� CEOs��.\"����.\"���.\"�� CEOs CEOs�.\"own.\".\".\"� CEOsown CEOs CEOs���.\"��.\".\"���ownownown������������������������������������ city city\n"
     ]
    }
   ],
   "source": [
    "# Print the first 30 predictions\n",
    "for i, pred in enumerate(model_preds):\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('plos_ireneli1024_bart-large-finetuned_model_preds.txt', 'w') as file:\n",
    "#   for string in model_preds:\n",
    "#     file.write(string + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Before clearing cache\n",
    "print(torch.cuda.memory_allocated())  # Print current memory allocated\n",
    "\n",
    "torch.cuda.empty_cache()  # Clear CUDA cache\n",
    "\n",
    "# After clearing cache\n",
    "print(torch.cuda.memory_allocated())  # Print current memory allocated again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Model finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"mse30/bart-base-finetuned-pubmed\", gradient_checkpointing=True, use_cache=False) \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mse30/bart-base-finetuned-pubmed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.num_beams = 2\n",
    "model.config.max_length = 512\n",
    "model.config.min_length = 100\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(\n",
    "        predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"]\n",
    "    )[\"rouge2\"].mid\n",
    "\n",
    "    return {\n",
    "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
